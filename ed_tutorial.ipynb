{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning\n",
    "\n",
    "In unsupervised learning, the task is to infer hidden structure from\n",
    "unlabeled data, comprised of training examples $\\{x_n\\}$.\n",
    "\n",
    "We demonstrate with an example in Edward. A webpage version is available at\n",
    "http://edwardlib.org/tutorials/unsupervised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/inf.ed.ac.uk/user/s12/s1202144/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /afs/inf.ed.ac.uk/user/s12/s1202144/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import edward as ed\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import six\n",
    "import tensorflow as tf\n",
    "ed.set_seed(42)\n",
    "from edward.models import (\n",
    "    Categorical, Dirichlet, Empirical, InverseGamma,\n",
    "    MultivariateNormalDiag, Normal, ParamMixture)\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Use a simulated data set of 2-dimensional data points\n",
    "$\\mathbf{x}_n\\in\\mathbb{R}^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_toy_dataset(N):\n",
    "  pi = np.array([0.4, 0.6])\n",
    "  mus = [[1, 1], [-1, -1]]\n",
    "  stds = [[0.1, 0.1], [0.1, 0.1]]\n",
    "  x = np.zeros((N, 2), dtype=np.float32)\n",
    "  for n in range(N):\n",
    "    k = np.argmax(np.random.multinomial(1, pi))\n",
    "    x[n, :] = np.random.multivariate_normal(mus[k], np.diag(stds[k]))\n",
    "\n",
    "  return x\n",
    "\n",
    "\n",
    "N = 500  # number of data points\n",
    "K = 2  # number of components\n",
    "D = 2  # dimensionality of data\n",
    "\n",
    "\n",
    "x_train = build_toy_dataset(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the generated data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEJCAYAAACAKgxxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYCciMpj/DyiMMciRr9tXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_train[:, 0], x_train[:, 1])\n",
    "plt.axis([-3, 3, -3, 3])\n",
    "plt.title(\"Simulated dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "A mixture model is a model typically used for clustering.\n",
    "It assigns a mixture component to each data point, and this mixture component\n",
    "determines the distribution that the data point is generated from. A\n",
    "mixture of Gaussians uses Gaussian distributions to generate this data\n",
    "(Bishop, 2006).\n",
    "\n",
    "For a set of $N$ data points,\n",
    "the likelihood of each observation $\\mathbf{x}_n$ is\n",
    "\n",
    "\\begin{align*}\n",
    "  p(\\mathbf{x}_n \\mid \\pi, \\mu, \\sigma)\n",
    "  &=\n",
    "  \\sum_{k=1}^K \\pi_k \\, \\text{Normal}(\\mathbf{x}_n \\mid \\mu_k, \\sigma_k).\n",
    "\\end{align*}\n",
    "\n",
    "The latent variable $\\pi$ is a $K$-dimensional probability vector\n",
    "which mixes individual Gaussian distributions, each\n",
    "characterized by a mean $\\mu_k$ and standard deviation $\\sigma_k$.\n",
    "\n",
    "Define the prior on $\\pi\\in[0,1]$ such that $\\sum_{k=1}^K\\pi_k=1$ to be\n",
    "\n",
    "\\begin{align*}\n",
    "  p(\\pi)\n",
    "  &=\n",
    "  \\text{Dirichlet}(\\pi \\mid \\alpha \\mathbf{1}_{K})\n",
    "\\end{align*}\n",
    "\n",
    "for fixed $\\alpha=1$. Define the prior on each component $\\mathbf{\\mu}_k\\in\\mathbb{R}^D$ to be\n",
    "\n",
    "\\begin{align*}\n",
    "  p(\\mathbf{\\mu}_k)\n",
    "  &=\n",
    "  \\text{Normal}(\\mathbf{\\mu}_k \\mid \\mathbf{0}, \\mathbf{I}).\n",
    "\\end{align*}\n",
    "\n",
    "Define the prior on each component $\\mathbf{\\sigma}_k^2\\in\\mathbb{R}^D$ to be\n",
    "\n",
    "\\begin{align*}\n",
    "  p(\\mathbf{\\sigma}_k^2)\n",
    "  &=\n",
    "  \\text{InverseGamma}(\\mathbf{\\sigma}_k^2 \\mid a, b).\n",
    "\\end{align*}\n",
    "\n",
    "We build two versions of the model in Edward: one jointly with the\n",
    "mixture assignments $c_n\\in\\{0,\\ldots,K-1\\}$ as latent variables,\n",
    "and another with them summed out.\n",
    "\n",
    "The joint version includes an explicit latent variable for the mixture\n",
    "assignments. We implement this with the `ParamMixture` random\n",
    "variable; it takes as input the mixing probabilities, the components'\n",
    "parameters, and the distribution of the components. It is the\n",
    "distribution of the mixture conditional on mixture assignments. (Note\n",
    "we can also write this separately by first building a `Categorical`\n",
    "random variable for `z` and then building `x`; `ParamMixture` avoids\n",
    "requiring `tf.gather` which is slightly more efficient.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = Dirichlet(tf.ones(K))\n",
    "mu = Normal(tf.zeros(D), tf.ones(D), sample_shape=K)\n",
    "sigmasq = InverseGamma(tf.ones(D), tf.ones(D), sample_shape=K)\n",
    "x = ParamMixture(pi, {'loc': mu, 'scale_diag': tf.sqrt(sigmasq)},\n",
    "                 MultivariateNormalDiag,\n",
    "                 sample_shape=N)\n",
    "z = x.cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collapsed version marginalizes out the mixture assignments. We\n",
    "implement this with the `Mixture` random variable; it takes as\n",
    "input a Categorical distribution and a list of individual distribution\n",
    "components. It is the distribution of the mixture summing out the\n",
    "mixture assignments. Gibbs sampling does not work with `Mixture` random\n",
    "variables, please try an alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npi = Dirichlet(tf.ones(K))\\nmu = Normal(tf.zeros(D), tf.ones(D), sample_shape=K)\\nsigmasq = InverseGamma(tf.ones(D), tf.ones(D), sample_shape=K)\\ncat = Categorical(probs=pi, sample_shape=N)\\ncomponents = [\\n    MultivariateNormalDiag(mu[k], tf.sqrt(sigmasq[k]), sample_shape=N)\\n    for k in range(K)]\\nx = Mixture(cat=cat, components=components)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "pi = Dirichlet(tf.ones(K))\n",
    "mu = Normal(tf.zeros(D), tf.ones(D), sample_shape=K)\n",
    "sigmasq = InverseGamma(tf.ones(D), tf.ones(D), sample_shape=K)\n",
    "cat = Categorical(probs=pi, sample_shape=N)\n",
    "components = [\n",
    "    MultivariateNormalDiag(mu[k], tf.sqrt(sigmasq[k]), sample_shape=N)\n",
    "    for k in range(K)]\n",
    "x = Mixture(cat=cat, components=components)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the joint version in this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Each distribution in the model is written with conjugate priors, so we\n",
    "can use Gibbs sampling. It performs Markov chain Monte Carlo by\n",
    "iterating over draws from the complete conditionals of each\n",
    "distribution, i.e., each distribution conditional on a previously\n",
    "drawn value. First we set up Empirical random variables which will\n",
    "approximate the posteriors using the collection of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable qpi/params already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-5-6badde4423dd>\", line 4, in <module>\n    initializer=tf.constant_initializer(1.0 / K)))\n  File \"/afs/inf.ed.ac.uk/user/s12/s1202144/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/afs/inf.ed.ac.uk/user/s12/s1202144/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6badde4423dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m qpi = Empirical(tf.get_variable(\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"qpi/params\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     initializer=tf.constant_initializer(1.0 / K)))\n\u001b[0m\u001b[1;32m      5\u001b[0m qmu = Empirical(tf.get_variable(\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m\"qmu/params\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1295\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m       constraint=constraint)\n\u001b[0m\u001b[1;32m   1298\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1299\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1091\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m           \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m    437\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m           \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    406\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m           use_resource=use_resource, constraint=constraint)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    745\u001b[0m                          \u001b[0;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 747\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    748\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable qpi/params already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-5-6badde4423dd>\", line 4, in <module>\n    initializer=tf.constant_initializer(1.0 / K)))\n  File \"/afs/inf.ed.ac.uk/user/s12/s1202144/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/afs/inf.ed.ac.uk/user/s12/s1202144/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "T = 500  # number of MCMC samples\n",
    "qpi = Empirical(tf.get_variable(\n",
    "    \"qpi/params\", [T, K],\n",
    "    initializer=tf.constant_initializer(1.0 / K)))\n",
    "qmu = Empirical(tf.get_variable(\n",
    "    \"qmu/params\", [T, K, D],\n",
    "    initializer=tf.zeros_initializer()))\n",
    "qsigmasq = Empirical(tf.get_variable(\n",
    "    \"qsigmasq/params\", [T, K, D],\n",
    "    initializer=tf.ones_initializer()))\n",
    "qz = Empirical(tf.get_variable(\n",
    "    \"qz/params\", [T, N],\n",
    "    initializer=tf.zeros_initializer(),\n",
    "    dtype=tf.int32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Gibbs sampling. We write the training loop explicitly, so that we can track\n",
    "the cluster means as the sampler progresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/inf.ed.ac.uk/user/s12/s1202144/miniconda3/lib/python3.6/site-packages/edward/util/random_variables.py:52: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  not np.issubdtype(value.dtype, np.float) and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5/500 [  1%]                                ETA: 60s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.2759056   0.36513087]\n",
      " [-0.57515204 -0.4851961 ]]\n",
      " 10/500 [  2%]                                ETA: 34s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.6337332   0.6816196 ]\n",
      " [-0.8102343  -0.74457484]]\n",
      " 15/500 [  3%]                                ETA: 23s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.7600507   0.79856604]\n",
      " [-0.87815946 -0.8262308 ]]\n",
      " 20/500 [  4%] █                              ETA: 18s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.821256    0.8551938 ]\n",
      " [-0.91282445 -0.860884  ]]\n",
      " 25/500 [  5%] █                              ETA: 15s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.8576469   0.8930318 ]\n",
      " [-0.9333708  -0.88464355]]\n",
      " 30/500 [  6%] █                              ETA: 13s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.8774287   0.91293865]\n",
      " [-0.9463699  -0.897863  ]]\n",
      " 35/500 [  7%] ██                             ETA: 11s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.8930952   0.9280443 ]\n",
      " [-0.955792   -0.90623397]]\n",
      " 40/500 [  8%] ██                             ETA: 10s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.90508527  0.94151413]\n",
      " [-0.9616976  -0.91244   ]]\n",
      " 45/500 [  9%] ██                             ETA: 9s | Acceptance Rate: 1.000 \n",
      "Inferred cluster means:\n",
      "[[ 0.91340387  0.9530523 ]\n",
      " [-0.96756494 -0.9208136 ]]\n",
      " 50/500 [ 10%] ███                            ETA: 9s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9205571   0.9598371 ]\n",
      " [-0.9714284  -0.92623234]]\n",
      " 55/500 [ 11%] ███                            ETA: 8s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9248877   0.965626  ]\n",
      " [-0.9759995  -0.93060875]]\n",
      " 60/500 [ 12%] ███                            ETA: 8s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9294316   0.97157466]\n",
      " [-0.97691566 -0.933343  ]]\n",
      " 65/500 [ 13%] ███                            ETA: 7s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9329264   0.97515935]\n",
      " [-0.9798252  -0.9363853 ]]\n",
      " 70/500 [ 14%] ████                           ETA: 7s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.93689704  0.97799927]\n",
      " [-0.9824683  -0.93816066]]\n",
      " 75/500 [ 15%] ████                           ETA: 7s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9396207   0.98044175]\n",
      " [-0.98421425 -0.94073886]]\n",
      " 80/500 [ 16%] ████                           ETA: 6s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.94393003  0.9831154 ]\n",
      " [-0.98588955 -0.9423627 ]]\n",
      " 85/500 [ 17%] █████                          ETA: 6s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.94657737  0.98547935]\n",
      " [-0.98729813 -0.9443581 ]]\n",
      " 90/500 [ 18%] █████                          ETA: 6s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.94819146  0.9872782 ]\n",
      " [-0.988577   -0.9465064 ]]\n",
      " 95/500 [ 19%] █████                          ETA: 6s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9498204   0.9888703 ]\n",
      " [-0.99077314 -0.94849914]]\n",
      "100/500 [ 20%] ██████                         ETA: 5s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9514453   0.99002635]\n",
      " [-0.9911339  -0.949232  ]]\n",
      "105/500 [ 21%] ██████                         ETA: 5s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9539657  0.9919652]\n",
      " [-0.9923707 -0.9510408]]\n",
      "110/500 [ 22%] ██████                         ETA: 5s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9558894   0.9938705 ]\n",
      " [-0.99346966 -0.9513203 ]]\n",
      "115/500 [ 23%] ██████                         ETA: 5s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9576153   0.99556714]\n",
      " [-0.99464893 -0.95150495]]\n",
      "120/500 [ 24%] ███████                        ETA: 5s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9580851  0.9967008]\n",
      " [-0.9953471 -0.9523262]]\n",
      "125/500 [ 25%] ███████                        ETA: 5s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.96005976  0.9976732 ]\n",
      " [-0.99649316 -0.9530181 ]]\n",
      "130/500 [ 26%] ███████                        ETA: 5s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9605546  0.9984908]\n",
      " [-0.9971724 -0.9534215]]\n",
      "135/500 [ 27%] ████████                       ETA: 4s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.96181977  1.0000385 ]\n",
      " [-0.9979411  -0.9543183 ]]\n",
      "140/500 [ 28%] ████████                       ETA: 4s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9618867  1.0009462]\n",
      " [-0.9983884 -0.9548833]]\n",
      "145/500 [ 28%] ████████                       ETA: 4s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.96221036  1.0014783 ]\n",
      " [-0.9988139  -0.95568424]]\n",
      "150/500 [ 30%] █████████                      ETA: 4s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.96261597  1.0022646 ]\n",
      " [-0.99917763 -0.955903  ]]\n",
      "155/500 [ 31%] █████████                      ETA: 4s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9635979   1.0028416 ]\n",
      " [-0.9994215  -0.95630735]]\n",
      "160/500 [ 32%] █████████                      ETA: 4s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.96452785  1.0036293 ]\n",
      " [-0.9999852  -0.95653147]]\n",
      "165/500 [ 33%] █████████                      ETA: 4s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9648864  1.0046878]\n",
      " [-1.0003076 -0.9570558]]\n",
      "170/500 [ 34%] ██████████                     ETA: 4s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.96525306  1.0056473 ]\n",
      " [-1.0004942  -0.9575015 ]]\n",
      "175/500 [ 35%] ██████████                     ETA: 4s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9654061   1.0063846 ]\n",
      " [-1.0005852  -0.95750725]]\n",
      "180/500 [ 36%] ██████████                     ETA: 3s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.96591836  1.0069853 ]\n",
      " [-1.0008688  -0.9579898 ]]\n",
      "185/500 [ 37%] ███████████                    ETA: 3s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.96658754  1.0074108 ]\n",
      " [-1.0009687  -0.95852876]]\n",
      "190/500 [ 38%] ███████████                    ETA: 3s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.96708333  1.0078003 ]\n",
      " [-1.0010233  -0.9587619 ]]\n",
      "195/500 [ 39%] ███████████                    ETA: 3s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.96720266  1.0082635 ]\n",
      " [-1.0015346  -0.95900536]]\n",
      "200/500 [ 40%] ████████████                   ETA: 3s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.96735716  1.0083789 ]\n",
      " [-1.0017203  -0.9591572 ]]\n",
      "205/500 [ 41%] ████████████                   ETA: 3s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.967497   1.0086279]\n",
      " [-1.0019047 -0.9594589]]\n",
      "210/500 [ 42%] ████████████                   ETA: 3s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9673793  1.0089813]\n",
      " [-1.0020809 -0.9597483]]\n",
      "215/500 [ 43%] ████████████                   ETA: 3s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.96815264  1.0093094 ]\n",
      " [-1.0023341  -0.95985705]]\n",
      "220/500 [ 44%] █████████████                  ETA: 3s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9685294   1.0093747 ]\n",
      " [-1.0024508  -0.96011406]]\n",
      "225/500 [ 45%] █████████████                  ETA: 3s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9686518  1.0096829]\n",
      " [-1.002472  -0.9602187]]\n",
      "230/500 [ 46%] █████████████                  ETA: 3s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9691184   1.0100408 ]\n",
      " [-1.0031322  -0.96037245]]\n",
      "235/500 [ 47%] ██████████████                 ETA: 3s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9691274  1.0105566]\n",
      " [-1.0034784 -0.9606135]]\n",
      "240/500 [ 48%] ██████████████                 ETA: 2s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.969615   1.0108141]\n",
      " [-1.0032252 -0.9609115]]\n",
      "245/500 [ 49%] ██████████████                 ETA: 2s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9696814  1.0108931]\n",
      " [-1.0034384 -0.9611186]]\n",
      "250/500 [ 50%] ███████████████                ETA: 2s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9699024   1.0112804 ]\n",
      " [-1.0036863  -0.96134585]]\n",
      "255/500 [ 51%] ███████████████                ETA: 2s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.97054523  1.0116976 ]\n",
      " [-1.0039173  -0.96138304]]\n",
      "260/500 [ 52%] ███████████████                ETA: 2s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9707491  1.0121742]\n",
      " [-1.0040723 -0.9617691]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265/500 [ 53%] ███████████████                ETA: 2s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9711179   1.0124334 ]\n",
      " [-1.0044497  -0.96194506]]\n",
      "270/500 [ 54%] ████████████████               ETA: 2s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.97086877  1.0128866 ]\n",
      " [-1.0043904  -0.9620452 ]]\n",
      "275/500 [ 55%] ████████████████               ETA: 2s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.97129875  1.0127695 ]\n",
      " [-1.0043272  -0.96208817]]\n",
      "280/500 [ 56%] ████████████████               ETA: 2s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.97162545  1.0129387 ]\n",
      " [-1.0045155  -0.9624618 ]]\n",
      "285/500 [ 56%] █████████████████              ETA: 2s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9720257   1.0131354 ]\n",
      " [-1.0048826  -0.96251947]]\n",
      "290/500 [ 57%] █████████████████              ETA: 2s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.97226524  1.0134531 ]\n",
      " [-1.0052773  -0.9625787 ]]\n",
      "295/500 [ 59%] █████████████████              ETA: 2s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.972606   1.0138503]\n",
      " [-1.0054048 -0.9626298]]\n",
      "300/500 [ 60%] ██████████████████             ETA: 2s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9726312  1.0144176]\n",
      " [-1.0055428 -0.9627895]]\n",
      "305/500 [ 61%] ██████████████████             ETA: 2s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.97296697  1.01454   ]\n",
      " [-1.0055997  -0.9628871 ]]\n",
      "310/500 [ 62%] ██████████████████             ETA: 2s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9734628  1.0147469]\n",
      " [-1.005693  -0.9629012]]\n",
      "315/500 [ 63%] ██████████████████             ETA: 1s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9734314  1.015038 ]\n",
      " [-1.0056849 -0.9631591]]\n",
      "320/500 [ 64%] ███████████████████            ETA: 1s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9737976  1.0152966]\n",
      " [-1.0057732 -0.9630021]]\n",
      "325/500 [ 65%] ███████████████████            ETA: 1s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9738526   1.0152473 ]\n",
      " [-1.0060956  -0.96313846]]\n",
      "330/500 [ 66%] ███████████████████            ETA: 1s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9742028  1.0150886]\n",
      " [-1.0062364 -0.9632088]]\n",
      "335/500 [ 67%] ████████████████████           ETA: 1s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9747477  1.0151894]\n",
      " [-1.0063412 -0.9633328]]\n",
      "340/500 [ 68%] ████████████████████           ETA: 1s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9749402  1.0153153]\n",
      " [-1.006567  -0.9635792]]\n",
      "345/500 [ 69%] ████████████████████           ETA: 1s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9749796   1.0154147 ]\n",
      " [-1.0064613  -0.96355784]]\n",
      "350/500 [ 70%] █████████████████████          ETA: 1s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9752199  1.0157127]\n",
      " [-1.0063955 -0.9635398]]\n",
      "355/500 [ 71%] █████████████████████          ETA: 1s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9752217  1.0157243]\n",
      " [-1.0064112 -0.9638283]]\n",
      "360/500 [ 72%] █████████████████████          ETA: 1s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9754771  1.0156877]\n",
      " [-1.0065961 -0.9638088]]\n",
      "365/500 [ 73%] █████████████████████          ETA: 1s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.97540575  1.0158054 ]\n",
      " [-1.0064995  -0.9638123 ]]\n",
      "370/500 [ 74%] ██████████████████████         ETA: 1s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9755386   1.0159738 ]\n",
      " [-1.0066807  -0.96390647]]\n",
      "375/500 [ 75%] ██████████████████████         ETA: 1s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.97563595  1.0160116 ]\n",
      " [-1.0067846  -0.96398145]]\n",
      "380/500 [ 76%] ██████████████████████         ETA: 1s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9756675  1.0160859]\n",
      " [-1.0066478 -0.9641928]]\n",
      "385/500 [ 77%] ███████████████████████        ETA: 1s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9759937  1.0160724]\n",
      " [-1.0067798 -0.9640421]]\n",
      "390/500 [ 78%] ███████████████████████        ETA: 1s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9760127  1.0160685]\n",
      " [-1.0068129 -0.964125 ]]\n",
      "395/500 [ 79%] ███████████████████████        ETA: 1s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9761588   1.0159822 ]\n",
      " [-1.0071666  -0.96424556]]\n",
      "400/500 [ 80%] ████████████████████████       ETA: 1s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.97621596  1.0161185 ]\n",
      " [-1.007126   -0.96432227]]\n",
      "405/500 [ 81%] ████████████████████████       ETA: 0s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.97639513  1.016207  ]\n",
      " [-1.0072483  -0.96444255]]\n",
      "410/500 [ 82%] ████████████████████████       ETA: 0s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.97663426  1.0161861 ]\n",
      " [-1.0073097  -0.9646877 ]]\n",
      "415/500 [ 83%] ████████████████████████       ETA: 0s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.97669894  1.0162735 ]\n",
      " [-1.0073344  -0.96466213]]\n",
      "420/500 [ 84%] █████████████████████████      ETA: 0s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.97678363  1.0163347 ]\n",
      " [-1.007187   -0.9646564 ]]\n",
      "425/500 [ 85%] █████████████████████████      ETA: 0s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9770431   1.0164831 ]\n",
      " [-1.007273   -0.96474236]]\n",
      "430/500 [ 86%] █████████████████████████      ETA: 0s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9769605   1.0164864 ]\n",
      " [-1.0072788  -0.96485376]]\n",
      "435/500 [ 87%] ██████████████████████████     ETA: 0s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9771183   1.0166247 ]\n",
      " [-1.00745    -0.96476895]]\n",
      "440/500 [ 88%] ██████████████████████████     ETA: 0s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9772401  1.0164859]\n",
      " [-1.0073872 -0.9649115]]\n",
      "445/500 [ 89%] ██████████████████████████     ETA: 0s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9772862  1.0165612]\n",
      " [-1.0072742 -0.964829 ]]\n",
      "450/500 [ 90%] ███████████████████████████    ETA: 0s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9773168  1.0167482]\n",
      " [-1.0073719 -0.9649635]]\n",
      "455/500 [ 91%] ███████████████████████████    ETA: 0s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9774198  1.0170143]\n",
      " [-1.007376  -0.965051 ]]\n",
      "460/500 [ 92%] ███████████████████████████    ETA: 0s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.97753567  1.017136  ]\n",
      " [-1.007396   -0.9650894 ]]\n",
      "465/500 [ 93%] ███████████████████████████    ETA: 0s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.97786456  1.0172527 ]\n",
      " [-1.0073518  -0.9651395 ]]\n",
      "470/500 [ 94%] ████████████████████████████   ETA: 0s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9778381  1.0172796]\n",
      " [-1.007385  -0.9653257]]\n",
      "475/500 [ 95%] ████████████████████████████   ETA: 0s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.97783893  1.017444  ]\n",
      " [-1.0074368  -0.9653733 ]]\n",
      "480/500 [ 96%] ████████████████████████████   ETA: 0s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.97781086  1.0175544 ]\n",
      " [-1.0075238  -0.9655596 ]]\n",
      "485/500 [ 97%] █████████████████████████████  ETA: 0s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9780712   1.0175442 ]\n",
      " [-1.0075549  -0.96554357]]\n",
      "490/500 [ 98%] █████████████████████████████  ETA: 0s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.9780579   1.017622  ]\n",
      " [-1.0075469  -0.96549314]]\n",
      "495/500 [ 99%] █████████████████████████████  ETA: 0s | Acceptance Rate: 1.000\n",
      "Inferred cluster means:\n",
      "[[ 0.97793484  1.0176576 ]\n",
      " [-1.0076709  -0.9655862 ]]\n",
      "500/500 [100%] ██████████████████████████████ Elapsed: 4s | Acceptance Rate: 1.000\n",
      "\n",
      "Inferred cluster means:\n",
      "[[ 0.9778021  1.0176687]\n",
      " [-1.0078006 -0.9656514]]\n"
     ]
    }
   ],
   "source": [
    "inference = ed.Gibbs({pi: qpi, mu: qmu, sigmasq: qsigmasq, z: qz},\n",
    "                     data={x: x_train})\n",
    "inference.initialize()\n",
    "\n",
    "sess = ed.get_session()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "t_ph = tf.placeholder(tf.int32, [])\n",
    "running_cluster_means = tf.reduce_mean(qmu.params[:t_ph], 0)\n",
    "\n",
    "for _ in range(inference.n_iter):\n",
    "  info_dict = inference.update()\n",
    "  inference.print_progress(info_dict)\n",
    "  t = info_dict['t']\n",
    "  if t % inference.n_print == 0:\n",
    "    print(\"\\nInferred cluster means:\")\n",
    "    print(sess.run(running_cluster_means, {t_ph: t - 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.9486212 ,  1.0353546 ],\n",
       "        [-1.006353  , -0.9584221 ]],\n",
       "\n",
       "       [[ 1.0037618 ,  1.0459365 ],\n",
       "        [-1.0137264 , -0.9877131 ]],\n",
       "\n",
       "       [[ 0.96683514,  0.97743946],\n",
       "        [-1.0437274 , -0.9677285 ]],\n",
       "\n",
       "       [[ 0.9296166 ,  1.0330362 ],\n",
       "        [-0.9956963 , -0.9401065 ]],\n",
       "\n",
       "       [[ 0.973614  ,  1.0387613 ],\n",
       "        [-0.9997834 , -0.95591336]],\n",
       "\n",
       "       [[ 1.004651  ,  1.0009398 ],\n",
       "        [-1.0380948 , -0.969842  ]],\n",
       "\n",
       "       [[ 0.9872291 ,  0.9999682 ],\n",
       "        [-1.0564986 , -0.974731  ]],\n",
       "\n",
       "       [[ 0.95448864,  1.0246148 ],\n",
       "        [-1.0039816 , -0.9606948 ]],\n",
       "\n",
       "       [[ 0.9743077 ,  1.0120431 ],\n",
       "        [-0.9566615 , -0.98715425]],\n",
       "\n",
       "       [[ 0.9817158 ,  1.0114447 ],\n",
       "        [-1.0063792 , -0.9670093 ]],\n",
       "\n",
       "       [[ 0.04662272,  0.15252519],\n",
       "        [-0.41019896, -0.32822242]],\n",
       "\n",
       "       [[ 1.0300987 ,  1.0409484 ],\n",
       "        [-1.0477569 , -0.97947454]],\n",
       "\n",
       "       [[ 0.9837777 ,  1.046701  ],\n",
       "        [-0.97061986, -0.9380374 ]],\n",
       "\n",
       "       [[ 0.95364654,  1.0458056 ],\n",
       "        [-1.0516797 , -0.95104015]],\n",
       "\n",
       "       [[ 0.95766807,  0.99191153],\n",
       "        [-0.99532944, -0.9813554 ]],\n",
       "\n",
       "       [[ 0.9774607 ,  1.0130756 ],\n",
       "        [-1.0146991 , -0.9746311 ]],\n",
       "\n",
       "       [[ 0.976741  ,  0.994208  ],\n",
       "        [-1.0094979 , -1.0057671 ]],\n",
       "\n",
       "       [[ 0.9616599 ,  1.0362533 ],\n",
       "        [-1.0298687 , -0.9595664 ]],\n",
       "\n",
       "       [[ 0.980714  ,  1.0186371 ],\n",
       "        [-1.0039119 , -0.96844155]],\n",
       "\n",
       "       [[ 0.9682979 ,  1.0419589 ],\n",
       "        [-1.0107421 , -0.9760422 ]],\n",
       "\n",
       "       [[ 0.9852157 ,  1.0385432 ],\n",
       "        [-1.0147059 , -1.0067109 ]],\n",
       "\n",
       "       [[ 0.9862733 ,  1.0310463 ],\n",
       "        [-1.0236281 , -0.95235234]],\n",
       "\n",
       "       [[ 0.99495494,  1.0660086 ],\n",
       "        [-1.0068469 , -1.0046562 ]],\n",
       "\n",
       "       [[ 0.97324264,  1.0228788 ],\n",
       "        [-1.0306137 , -1.0083948 ]],\n",
       "\n",
       "       [[ 0.97564137,  0.9960515 ],\n",
       "        [-1.0228956 , -1.0018116 ]],\n",
       "\n",
       "       [[ 0.99490404,  1.0402977 ],\n",
       "        [-1.0211948 , -0.98119605]],\n",
       "\n",
       "       [[ 0.98398834,  1.0038838 ],\n",
       "        [-1.0059351 , -0.963081  ]],\n",
       "\n",
       "       [[ 0.98985153,  1.0488147 ],\n",
       "        [-1.0058812 , -0.97486746]],\n",
       "\n",
       "       [[ 0.9509    ,  0.9946872 ],\n",
       "        [-0.9959699 , -0.93973213]],\n",
       "\n",
       "       [[ 0.99007124,  1.0310197 ],\n",
       "        [-0.9749695 , -0.9673552 ]],\n",
       "\n",
       "       [[ 0.97477424,  1.0643713 ],\n",
       "        [-1.0167631 , -0.9417905 ]],\n",
       "\n",
       "       [[ 0.9810425 ,  1.0434604 ],\n",
       "        [-0.96674335, -0.990391  ]],\n",
       "\n",
       "       [[ 0.9950175 ,  1.0025299 ],\n",
       "        [-0.9998016 , -0.98702335]],\n",
       "\n",
       "       [[ 0.9703818 ,  1.0143901 ],\n",
       "        [-0.9916997 , -0.9678125 ]],\n",
       "\n",
       "       [[ 0.9810425 ,  1.0434604 ],\n",
       "        [-0.96674335, -0.990391  ]],\n",
       "\n",
       "       [[ 0.9956126 ,  1.0252851 ],\n",
       "        [-0.99195516, -0.95991033]],\n",
       "\n",
       "       [[ 1.0057732 ,  1.0023847 ],\n",
       "        [-1.0738112 , -0.9728145 ]],\n",
       "\n",
       "       [[ 0.9605992 ,  1.0338784 ],\n",
       "        [-1.0309936 , -0.95593685]],\n",
       "\n",
       "       [[ 0.9694741 ,  1.0285116 ],\n",
       "        [-1.0122195 , -0.9526377 ]],\n",
       "\n",
       "       [[ 0.9822301 ,  1.002452  ],\n",
       "        [-1.0008471 , -0.9682178 ]],\n",
       "\n",
       "       [[ 0.9608272 ,  0.98017895],\n",
       "        [-1.0117916 , -0.9964215 ]],\n",
       "\n",
       "       [[ 0.98398834,  1.0038838 ],\n",
       "        [-1.0059351 , -0.963081  ]],\n",
       "\n",
       "       [[ 1.0042021 ,  1.0644103 ],\n",
       "        [-1.0101463 , -0.9789505 ]],\n",
       "\n",
       "       [[ 1.0101535 ,  1.0627567 ],\n",
       "        [-1.0065778 , -0.9993164 ]],\n",
       "\n",
       "       [[ 0.97651577,  1.0514703 ],\n",
       "        [-0.99083275, -1.0009006 ]],\n",
       "\n",
       "       [[ 1.0013845 ,  1.006784  ],\n",
       "        [-1.0008522 , -0.97866416]],\n",
       "\n",
       "       [[ 0.9848159 ,  1.0254158 ],\n",
       "        [-1.0296742 , -0.9716408 ]],\n",
       "\n",
       "       [[ 0.9852157 ,  1.0385432 ],\n",
       "        [-1.0147059 , -1.0067109 ]],\n",
       "\n",
       "       [[ 0.9833086 ,  1.0251043 ],\n",
       "        [-1.0049821 , -0.9696209 ]],\n",
       "\n",
       "       [[ 0.9670457 ,  1.0202202 ],\n",
       "        [-1.0347158 , -0.95922434]],\n",
       "\n",
       "       [[ 0.91768837,  1.0070529 ],\n",
       "        [-1.046381  , -0.96879315]],\n",
       "\n",
       "       [[ 0.96813935,  1.0001765 ],\n",
       "        [-1.0202007 , -0.9640039 ]],\n",
       "\n",
       "       [[ 1.0080907 ,  1.0159441 ],\n",
       "        [-1.0055343 , -0.98005766]],\n",
       "\n",
       "       [[ 0.9885251 ,  1.017154  ],\n",
       "        [-1.0008546 , -0.96638566]],\n",
       "\n",
       "       [[ 0.98906857,  1.0105705 ],\n",
       "        [-0.9752104 , -0.9493603 ]],\n",
       "\n",
       "       [[ 0.99600893,  1.0021397 ],\n",
       "        [-1.0258483 , -1.0007789 ]],\n",
       "\n",
       "       [[ 0.9659838 ,  1.0423895 ],\n",
       "        [-0.9980518 , -0.980973  ]],\n",
       "\n",
       "       [[ 0.99907905,  1.0212433 ],\n",
       "        [-0.9856591 , -0.95498717]],\n",
       "\n",
       "       [[ 1.0035323 ,  1.038895  ],\n",
       "        [-1.0295421 , -0.95544744]],\n",
       "\n",
       "       [[ 0.94843507,  1.0117351 ],\n",
       "        [-0.9839059 , -0.99012303]],\n",
       "\n",
       "       [[ 0.9734113 ,  1.0264682 ],\n",
       "        [-1.0224693 , -0.9966871 ]],\n",
       "\n",
       "       [[ 0.9885251 ,  1.017154  ],\n",
       "        [-1.0008546 , -0.96638566]],\n",
       "\n",
       "       [[ 0.9817706 ,  0.98549366],\n",
       "        [-1.0154885 , -0.96046543]],\n",
       "\n",
       "       [[ 0.9509287 ,  1.0078572 ],\n",
       "        [-0.9902449 , -0.9611315 ]],\n",
       "\n",
       "       [[ 1.0054656 ,  0.93194485],\n",
       "        [-1.039396  , -0.96234703]],\n",
       "\n",
       "       [[ 0.9848269 ,  1.0292671 ],\n",
       "        [-0.9921866 , -1.0088711 ]],\n",
       "\n",
       "       [[ 0.98490375,  1.0351578 ],\n",
       "        [-1.0016394 , -0.98080856]],\n",
       "\n",
       "       [[ 0.9736814 ,  1.0341687 ],\n",
       "        [-1.044033  , -0.9881208 ]],\n",
       "\n",
       "       [[ 0.93986934,  1.0487739 ],\n",
       "        [-1.0060436 , -0.98494077]],\n",
       "\n",
       "       [[ 0.9834756 ,  1.0487187 ],\n",
       "        [-0.9949645 , -0.9348373 ]],\n",
       "\n",
       "       [[ 0.98985153,  1.0488147 ],\n",
       "        [-1.0058812 , -0.97486746]],\n",
       "\n",
       "       [[ 1.007488  ,  1.0347143 ],\n",
       "        [-1.0010992 , -0.9855181 ]],\n",
       "\n",
       "       [[ 0.98714656,  1.039579  ],\n",
       "        [-1.0121853 , -0.9908896 ]],\n",
       "\n",
       "       [[ 0.9616599 ,  1.0362533 ],\n",
       "        [-1.0298687 , -0.9595664 ]],\n",
       "\n",
       "       [[ 0.9774783 ,  1.0056019 ],\n",
       "        [-1.0001669 , -1.0018804 ]],\n",
       "\n",
       "       [[ 1.0397385 ,  0.9962042 ],\n",
       "        [-0.9764541 , -0.9702105 ]],\n",
       "\n",
       "       [[ 1.0000255 ,  1.0728859 ],\n",
       "        [-1.0391414 , -0.98847795]],\n",
       "\n",
       "       [[ 0.9461723 ,  1.0549786 ],\n",
       "        [-0.981105  , -0.97420126]],\n",
       "\n",
       "       [[ 1.0194242 ,  0.99953514],\n",
       "        [-1.0312415 , -0.9694245 ]],\n",
       "\n",
       "       [[ 0.9724949 ,  1.0293789 ],\n",
       "        [-1.0040566 , -0.95859873]],\n",
       "\n",
       "       [[ 0.99146914,  0.98639935],\n",
       "        [-0.9790556 , -0.99983376]],\n",
       "\n",
       "       [[ 0.9996015 ,  1.0393822 ],\n",
       "        [-1.049021  , -0.97832716]],\n",
       "\n",
       "       [[ 0.97818494,  1.0573186 ],\n",
       "        [-1.0372938 , -0.9767051 ]],\n",
       "\n",
       "       [[ 1.0155482 ,  1.0086555 ],\n",
       "        [-1.0397501 , -0.9527239 ]],\n",
       "\n",
       "       [[ 0.9516833 ,  1.0390168 ],\n",
       "        [-1.018031  , -0.96091026]],\n",
       "\n",
       "       [[ 1.0104965 ,  1.066643  ],\n",
       "        [-1.0164683 , -0.9623135 ]],\n",
       "\n",
       "       [[ 0.9994791 ,  1.0402154 ],\n",
       "        [-1.0095253 , -1.0150462 ]],\n",
       "\n",
       "       [[ 0.95088613,  1.0477874 ],\n",
       "        [-0.97736794, -0.9630848 ]],\n",
       "\n",
       "       [[ 1.0140816 ,  1.0081869 ],\n",
       "        [-1.0022627 , -0.9699711 ]],\n",
       "\n",
       "       [[ 0.97666925,  1.0363009 ],\n",
       "        [-1.0146453 , -0.9419835 ]],\n",
       "\n",
       "       [[ 0.98416793,  1.0564636 ],\n",
       "        [-0.99755627, -0.9664559 ]],\n",
       "\n",
       "       [[ 1.0227041 ,  1.0470297 ],\n",
       "        [-1.0093784 , -0.95672333]],\n",
       "\n",
       "       [[ 0.9874599 ,  0.9929313 ],\n",
       "        [-1.0007836 , -0.9502432 ]],\n",
       "\n",
       "       [[ 1.0227041 ,  1.0470297 ],\n",
       "        [-1.0093784 , -0.95672333]],\n",
       "\n",
       "       [[ 0.98490375,  1.0351578 ],\n",
       "        [-1.0016394 , -0.98080856]],\n",
       "\n",
       "       [[ 0.9701619 ,  0.9951274 ],\n",
       "        [-1.0180302 , -0.9578848 ]],\n",
       "\n",
       "       [[ 0.42488658,  0.46003777],\n",
       "        [-0.63939697, -0.6197127 ]],\n",
       "\n",
       "       [[ 0.9995336 ,  0.99338436],\n",
       "        [-0.99687725, -1.0098356 ]],\n",
       "\n",
       "       [[ 1.0102843 ,  1.026924  ],\n",
       "        [-1.0326339 , -0.9564545 ]],\n",
       "\n",
       "       [[ 0.978076  ,  1.0172377 ],\n",
       "        [-1.0408807 , -0.97777975]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(qmu.sample(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criticism\n",
    "\n",
    "We visualize the predicted memberships of each data point. We pick\n",
    "the cluster assignment which produces the highest posterior predictive\n",
    "density for each data point.\n",
    "\n",
    "To do this, we first draw a sample from the posterior and calculate a\n",
    "a $N\\times K$ matrix of log-likelihoods, one for each data point\n",
    "$\\mathbf{x}_n$ and cluster assignment $k$.\n",
    "We perform this averaged over 100 posterior samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Normal_3/log_prob/sub:0\", shape=(500, 100, 2, 2), dtype=float32)\n",
      "Tensor(\"Sum_2:0\", shape=(500, 100, 2), dtype=float32)\n",
      "Tensor(\"Mean_3:0\", shape=(500, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Calculate likelihood for each data point and cluster assignment,\n",
    "# averaged over many posterior samples. ``x_post`` has shape (N, 100, K, D).\n",
    "mu_sample = qmu.sample(100)\n",
    "sigmasq_sample = qsigmasq.sample(100)\n",
    "x_post = Normal(loc=tf.ones([N, 1, 1, 1]) * mu_sample,\n",
    "                scale=tf.ones([N, 1, 1, 1]) * tf.sqrt(sigmasq_sample))\n",
    "x_broadcasted = tf.tile(tf.reshape(x_train, [N, 1, 1, D]), [1, 100, K, 1])\n",
    "\n",
    "# Sum over latent dimension, then average over posterior samples.\n",
    "# ``log_liks`` ends up with shape (N, K).\n",
    "log_liks = x_post.log_prob(x_broadcasted)\n",
    "print(log_liks)\n",
    "log_liks = tf.reduce_sum(log_liks, 3)\n",
    "print(log_liks)\n",
    "log_liks = tf.reduce_mean(log_liks, 1)\n",
    "print(log_liks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then take the $\\arg\\max$ along the columns (cluster assignments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the cluster with the highest likelihood for each data point.\n",
    "clusters = tf.argmax(log_liks, 1).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the data points, colored by their predicted membership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEJCAYAAACAKgxxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xl8E0X/B/DP7uY+eqUtpaW0lKMc\niiByKodQ5BAFUREeBEEeRTkE8UIQEQEBfRABUQ5FQQ455FbhZ5Hbyn0jBUoLCKWld5s7u/P7I21o\nmk3btGkLYd6vFy/NZrM7kzTfnczMfochhBBQFEVRPoOt6QJQFEVR3kUDO0VRlI+hgZ2iKMrH0MBO\nURTlY2hgpyiK8jE0sFMURfkYGth9TEpKChiGwcGDB0UfV7dPPvkEDRo0qNQxGIbBqlWrvFQi31DT\nnyt1b6OBvYoNGzYMDMOAYRhIJBJERUXhjTfeQGZmZrWcPzIyEqmpqWjbtm259j948CAYhkFKSkrV\nFqwG+UIdPf1c7ycSiQQ//vhjTRfjvkYDezXo2LEjUlNTkZKSggULFuCXX37B0KFD3e5vsVi8dm6O\n4xAWFgapVOq1Y1J3efOz8gT9XKnS0MBeDWQyGcLCwlCnTh307dsX48ePx86dO2E0Gh0/qVevXo3e\nvXtDrVZj0qRJAIArV67g+eefR0BAAAIDA/HUU0/h7NmzTsdev349GjRoAIVCgQ4dOuDMmTNOz4v9\nZE9PT8fw4cNRq1YtKBQKxMbGYvny5UhJSUHHjh0BAPXq1QPDMOjSpYvjdT///DNatGgBhUKB6Oho\nTJgwAXq93vG82WzGm2++CX9/fwQGBuLNN9+E2Wwu8/0pKCjA+PHjERkZCblcjujoaHz22Wdu9xfr\nmomLi8OwYcMcj7du3YqWLVtCpVIhICAAbdq0wcmTJytdxy5dumDEiBGYMmUKateujYiICNEyEkLw\n2muvoX79+lAqlYiJicGkSZOc3o9///0Xzz//PIKDgx37fPHFF2XWARD/XE+ePIl27dpBoVCgUaNG\n2LhxI6KjozFjxgyn9+6bb77BkCFDoNVqERkZic8//9yp7NHR0ZgyZYrjswwNDcXXX38Ns9mMsWPH\nIjAwEBEREfj666+dXldQUIBx48YhIiICKpUKLVu2xKZNmxzPF5V5/fr1eOaZZ6BSqRATE4OffvrJ\n6dw8z2P48OGOX7oAkJeXh+HDhyMsLAxyuRyRkZGYMGGC6HtPASBUlXrllVdIt27dnLbNnTuXACB5\neXkkOTmZACARERHkp59+IklJSeTq1avk9u3bpFatWuSNN94gZ86cIRcvXiRjxowhQUFBJD09nRBC\nyIkTJwjDMGTixInk4sWL5JdffiHR0dEEADlw4AAhhDiOX/TYYDCQxo0bk5YtW5I//viDJCUlkV27\ndpG1a9cSm81Gtm7dSgCQI0eOkNTUVJKZmUkIIeSHH34gAQEBZOXKlSQpKYns27ePPPzww+Tll192\n1Gv8+PEkJCSEbNmyhfzzzz/knXfeIVqtltSvX9/t+yMIAuncuTOpV68e2bx5s+PYS5cudewDgPz0\n009uHxNCSLdu3cgrr7xCCCEkNTWVSKVSMmfOHHL16lVy4cIFsnr1anLmzJlK17Fz585Eo9GQkSNH\nkvPnz5MzZ86I1ovneTJ58mTy999/k+TkZLJ161YSFhZGPv74Y8c+zzzzDOnWrRs5efIkSU5OJn/+\n+SdZs2ZNmXUQ+1z1ej0JCwsjffr0IadPnyYJCQmkffv2RKlUkunTpzu9d6GhoWTp0qXkypUrZP78\n+QQA+fPPPx37REVFEX9/fzJ37lxy+fJlMn36dMIwDOnVq5dj22effUYYhiHnz593fI5dunQhnTt3\nJgcOHCBJSUlkyZIlRCqVkvj4eKcy16tXj6xbt45cvnyZfPDBB4TjOHLp0iVCCCHp6emE4zjy1Vdf\nkdTUVJKamkoIIWTs2LGkefPm5O+//ybXrl0jhw4dcvoboZzRwF7FSgb28+fPk5iYGNK2bVtCyN0/\n9k8//dTpdVOnTnXsU0QQBBITE0PmzZtHCCFk8ODBpH379k77LFy4sNTA/t133xG5XE5u3LghWt4D\nBw4QACQ5Odlpe1RUFPn222+dtu3bt48AIFlZWaSgoIDI5XKXL1urVq1KDezx8fEEADl69KjbfTwN\n7CdOnBCtQ2XrSIg9sDds2JDwPO+2vO58+eWXpEGDBo7HzZs3J1OnThXdt6w6lPxcly5dStRqNcnJ\nyXHs888//xAALoF97NixTseKjY0lEydOdDyOiooiffv2dTzmeZ5otVrSp08fp20BAQFk4cKFhBBC\n9uzZQ+RyudP5CSFk+PDhjmMVlXnu3LmO561WK1Gr1WTx4sWObRzHkR9++MHpOM8++6zj86XKJqme\n3wUPtr1790Kj0YDneZjNZnTr1g1Llixx2qdNmzZOj48ePYrjx49Do9E4bTcajbh8+TIA4MKFC+jW\nrZvT80888USpZTl+/DiaNm2KOnXqlLv8d+7cwbVr1zBhwgS8++67ju2kMH/clStXIJfLYTab0aFD\nB5fy7Nixo9TyBAYG4rHHHit3ecrSvHlz9OjRAw899BC6d++OLl26oH///oiMjHT7mvLUsXXr1gCA\nVq1agWXL7sVctmwZvvvuO6SkpECv18Nms0EQBMfz48ePx8iRI/H777+jS5cuePrpp9GpU6cK1eHC\nhQto0qQJ/P39HdsaN26MgIAAl31btGjh9DgiIgJpaWlO2x555BHH/7Msi5CQEDRv3txpW2hoKNLT\n0wHY/14tFotL15TFYkHDhg3dnl8ikaBWrVou5y9p1KhReP7553Hs2DF069YNPXv2RI8ePcr1OTyI\naGCvBm3btsWKFSsgkUhQu3ZtyOVyl33UarXTY0EQ0K1bN5d+TACOLy8hxNEH6QlPX1MUjObPn48n\nn3zS5fk6deogMTGxQseuyGsYhnEE3CJWq9Xx/xzH4ffff8fRo0cRHx+PX375BRMnTsSGDRvQp08f\n0WOWp45FSn5WYjZs2IDRo0dj9uzZ6Ny5M/z8/LBhwwZMnjzZsc/w4cPRs2dP7Ny5E3v27EGvXr3w\n3HPPYdWqVRWqQ3nfR5lM5vK64hccAC6DsgzDiG4rep0gCPD398fRo0fLPF95zl9Sjx49cP36deza\ntQt79+7Fyy+/jIcffhi7d+8Gx3GlvvZBRC931UCpVKJBgwaIjo4WDepiHnvsMZw/fx4RERFo0KCB\n07+QkBAAQLNmzXDo0CGn15V8XFKrVq1w/vx5/Pvvv6LPF33peJ53bKtVqxYiIyORmJjoUpaigdsG\nDRpAJpO5nP+vv/4qszxZWVk4duxYqfsVFxoailu3bjkem81mXLhwwWkfhmHQpk0bTJo0Cfv370fn\nzp3xww8/VKqOnti/fz9atmyJCRMmoFWrVmjYsKHo9MratWtj+PDhWLlyJb7//nusXr0aeXl5Zdah\npKZNm+Kff/5Bbm6uY1tiYiJycnI8KndFPfbYY8jJyYHJZHJ57+rWrevRsWQymdNnUyQoKAiDBg3C\nkiVL8Ouvv2Lfvn0unztlRwP7PWrMmDHgeR79+vXDgQMHkJKSgoMHD2Ly5MmOYPn2228jISEBkydP\nxqVLl7B582bMnTu31OMOGjQIUVFRePbZZxEfH4/k5GTs3r0b69atAwBERUWBZVn89ttvSE9PdwSK\nmTNnYsGCBZgxYwbOnTuHxMREbNmyBSNHjgRgb8W+8cYb+Oijj7Bt2zYkJibi/fffx8WLF0stT9eu\nXdGxY0e89NJL2Lp1K5KTk3Ho0CF89913bl8TFxeHxYsXIyEhAefOncOwYcOcph3+9ddfmD59Og4f\nPozr169j9+7dOHPmDJo2bVqpOnoiNjYWZ8+exdatW5GUlIT58+c7zRAB7J/xb7/9hqSkJJw/fx6b\nNm1CZGQktFptmXUoafDgwdBoNBg6dCjOnDmDw4cPY8SIEVAqlRX6FeWprl27Ii4uDv3798fmzZtx\n9epVHD9+HAsXLsSyZcs8Ola9evWwZ88e3Lp1CxkZGQCAyZMnY9OmTUhMTMTly5exevVqaDQajy8a\nD4ya7eL3fWKzYoorOQhWXEpKCvnPf/5DgoODiUwmI3Xr1iWDBw8mV69edeyzdu1aEhMTQ2QyGWnT\npg3ZsmVLqYOnhNhnXAwZMoTodDoil8tJbGys02DVnDlzSHh4OGFZlnTu3NmxffPmzaRdu3ZEqVQS\nrVZLHnnkETJt2jTH8waDgbz++uvEz8+P+Pn5kddee41MnDix1MFTQgjJy8sjY8aMIWFhYUQqlZLo\n6Ggya9Ysx/MoMViamppK+vTpQ7RaLalTpw755ptvnAZPz507R3r16kVq1arleN/effddYjabK13H\nzp07kxEjRpRaH0IIsVgs5PXXXyeBgYFEq9WSQYMGOQa2i4waNYo0bNiQKBQKEhQURHr37k3OnTtX\nrjqIfa4nTpwgbdu2JTKZjDRo0IBs2LCBhISEkP/9739u30tCnAeeCbEPnhYfcCWEkPr167sM9MbG\nxpLJkyc7HhsMBvLBBx+Q6OhoIpVKSa1atUiPHj3I7t273ZZZ7Ni///47ady4MZHJZI7369NPPyXN\nmjUjarWa+Pn5kU6dOol+Zyg7hhC6ghJF+aJr164hOjoa27ZtwzPPPFPTxaGqEQ3sFOUjVq1ahYiI\nCNSrVw/Xrl3D+++/j7S0NCQmJpZ7bIfyDZWeFWOxWDB16lTYbDbwPI927dphwIAB3igbRVEeyMzM\nxNSpU3Hz5k0EBQXh8ccfx4YNG2hQfwBVusVOCIHZbIZCoYDNZsPHH3+MYcOGoVGjRt4qI0VRFOWB\nSs+KYRjGMRWM53nwPF8to/AURVGUOK/coCQIAj744APcvn0bPXr0cLnTDADi4+MRHx8PAJg9e7Y3\nTktRFEWJ8OrgqV6vx//+9z8MHz68zPmlxW8w8TXBwcGO+be+yJfr58t1A2j97nfh4eHl2s+rNyip\n1Wo0bdoUp06d8uZhKYqiKA9UOrDn5eU58lVbLBacPXvWbY5qiqIoqupVuo89OzsbixYtgiAIIISg\nffv2aNWqlTfKRlEURVVApQN7VFSUywosFEVRVM2hScAoiqJ8DA3sFEVRPoYGdoqiKB9DAztFUZSP\noYGdoijKx9DATlEU5WNoYKcoivIxNLBTFEX5GBrYKYqifAwN7BRFUT6GBnaKoigfQwM7RVGUj6GB\nnaIoysfQwE5RFOVjaGCnKIryMTSwUxRF+Rga2CmKonwMDewURVE+hgZ2iqIoH1PpNU8pivIN6eks\nvv1WjfR0Dn37GtG9uxkMU9OloiqCBnaKonD0qBRjxwbixg17SNi1S4G4OBO+/TaHBvf7EO2KoSgK\nn33m5wjqAGA0stizR46//5bWYKmoiqKBnaIecIQAqamcy/aCAg7btilroERUZdHATlEPOIYB1Gri\nsp1lCRo2tNVAiajKooGdoij06mWEUik4bWvQwIZBgww1VCKqMujgKUVReOedAkilBDt3KmE0Mqhb\n14aZM/OgpD0x9yUa2CmKAsMA48bpMW6cvqaLQnlBpQN7RkYGFi1ahJycHDAMg7i4OPTu3dsbZaMo\niqIqoNKBneM4DBkyBDExMTAajZg4cSKaN2+OOnXqeKN8FEVRlIcqPXgaGBiImJgYAIBSqURERASy\nsrIqXTCKoiiqYrw6KyY9PR3Jyclo0KCBNw9LURRFeYAhhLhOYK0Ak8mEqVOnon///mjbtq3L8/Hx\n8YiPjwcAzJ49GxaLxRunvSdJJBLYbL47/9eX6+fLdQNo/e53MpmsXPt5JbDbbDbMmTMHjzzyCPr0\n6VOu19y6dauyp71nBQcHIyMjo6aLUWV8uX6+XDeA1u9+Fx4eXq79Kt0VQwjB4sWLERERUe6gTlEU\nRVWdSs+KSUxMxP79+1G3bl289957AIBBgwbh0UcfrXThKIqiKM9VOrA3btwY69ev90ZZKIqiKC+g\nuWIoiqJ8DE0pQFH3IUKAS5ckIASIjbXRxTAoJzSwU9R9JjGRw/jxgUhOtn99o6NtmDcvB02aVH6a\nn9UKbN6sREKCDO3aWdC/vxFSutbGfYcGdoq6jxACjBsXiLNn785nPntWhnHjArBrV4Zoyz0xkcPU\nqf64eZODvz+HHj3UGDNGD4axr3OamcmiQQMbLBYGgwYF4cwZGaxWBps2qbBqlRpr12ZCo/HK7S5U\nNaGBnaJqSHIyh4QEOZo2taBFi/K1ti9ckODqVdev7dWrEpw9K0Xz5lan7bm5DP773yBcvXq32f3P\nP1pYLAzOnZPi9GkZCgoYRETwCA+34fhxuWM/m43BiRMy/O9/WnzySV4Fa0nVBBrYKaqaEQJMmOCP\nP/9UICODg1YroGVLC5Yvzyoz/7kgMBC7pVAQAJ533b5smdopqAOAycTi++/VyM29uxzepUssUlJc\nl8cDgPPnaV/M/YbOiqGoarZpkwLbtimRkWEPpPn5LPbvl+Ozz/zKfG2zZlZER7u27mNieDzyiNVl\n+6FDcpdtAJCX5/rVt1jEw4FKJYhup+5dNLBTVDXbsUMJk6nkV4/BqVNl5wFhWeCLL3LQpIkVMpkA\nmUxA48ZWzJmTDVbk2+xp2hS53DmI63Q8Xn/d+4tvWK3AmjVKvPVWAFatUsGHU0fVCNoVQ1HVzN0s\nE44r3wBlixY27Np1BydPSkEI8OijVnDivSgIDhZvbatUBHq980irnx+PcePysW2bCllZLIKDBYwY\nUYDHH/du1NXrGQwcqMOZM1LYbAy2blVizRoVfv45E35+dJDWG2iLnaKq2auvFiAgwLlDXCYT0L27\nqdzH4DjgscesaN3afVAH4HZ+e0QEj9atzU4t9Lw8BnPm+OHqVQksFvuFpkED72dK/N//NDhxQgab\nzV44m43B6dMyfP651uvnelDRwE5R1axdOyvGjStAw4ZWBATwiI62YvBgA0aN8l6Xh9kMrFypwunT\n4j8P/P0FfPNNNtTq4i16FhYLi/x8FmlpEhw7Jsfo0YEwGr1799P27eIjxHSQ1ntoVwxF1YDXX9dj\n2DA9UlM5hIQIUKm81wWRns7ixRd1uHpVAkEQD8oZGSzWrlUhK6v0EHD1qgTr1yvxyisGr5RNEIDc\nXPH2ZH4+vX3WW2hgp6hqkp/PYNIkf1y4IIVEQtCunQUffZRXoTs7V6xQYu1aNXJzWYSECBg9Oh89\nephx8qQEgwfrnKYyiklJkWDjRkWZ5yGEQUKCFJs365CdzSIoSMCoUQXo3t3seaFhHzRVqQgMIteJ\nhg19d4GM6kYDO0VVA0KAYcOC8Pffd6cf/vOPFFlZLBYuzPHoWNu2KTBnjr+j5Xv9OjBxYgDCwjLx\n9tuBZQZ1e3kYXL9e9hVFIhFw6JACWVl3j5mSIsF332WhVSvX6ZVlkcuBqCibY6pnEaVSwOjRBR4f\njxJH+9gpqhqcOiXFuXPOgZTnGRw6JMPEiX748EM/XLpUvnbWqlUql+6M9HQOU6f6id6V6l7ZXR8S\nCZyCetG5hg4NQv/+OixYoIHg4TT3jz7KR926d1vnGo2Avn2NeOgh2mL3Ftpip6hqkJzMoaDAtR2V\nlsbhp580AIBfflFh7Nh8jB1b+iCq6xx4u+vXOdG7TyuDZcX7/nNyOBw+zOHkSRmuXeMwd25umcci\nBPjjDzk2blSheXMLOnQwgxBgwAAD2rb1vPVPuUcDO0VVgyeesCAszIbbt0t+5e62mvV6FsuWaTBk\niAEBAe4HU+vWteL4cdebmdLS7H333lzL2WAo/Ue9xcJg7145Jkzww82bUgQECBg/Pl800+TEif7Y\ntEnpOKZOx+P99/PQrh0N6t5Gu2IoqhqEhgro398IP7/S+y0yMzkkJJR+Byoh7rtQ7HPDvXmTT9nd\nNbdvc1i3ToODB+XYsUOJIUOCcPSoc7fTjRscdu5UOF0oMjM5LF+u8eqFiLKjgZ2iqsnkyflYsSIT\nzz9vQEiIeDRjWYLw8NKD/+XL99oPbefgn5oqwdy5zjcb7dsndxkwBexTM2/dKnuwl/IMDewUVY3a\ntLFiwYIcDBligFjLmmGAefM0SEtz/9Us7U7TwqOIbKuaW/XdpUHIynIuf2ysFWq16wCAnx+BTkeT\njHkbDewUVQNGjy5AmzYWsGxRULMHSJ5n8McfSnToEIonnwzByJGByMpyDtTt25vheaD2dhcN4Ocn\noEcPo+hzgYHO53rsMSuaN3f+lSKTEXTsaIZaTfPDeBsN7BRVAxQK4JdfMrFgQQ60WgElW9kmE4tL\nl6TYsUOJgQN1OHRIhqwsBmYzkJQkKcwBU5Hg7j2xsVbMnZuLxo2dBz/DwmwYNy7f+cwMsGJFFgYO\n1OOhhyxo2dKC0aMLMGuW+9k0WVksli5VYcUKFQoK6F2pnmAIEUvbX/Vu3bpVE6etFsHBwcjIyKjp\nYlQZX65fddTtyBEpli7VwGBg0KyZFRs3qpCeXlr/iv0rKpPZuy1SUzl4O0h7jqB2bQGtWlnw1lv5\nWL5cjZQUCfz9Bbz1Vr5jRSijEbhyRYpatXiEhpbe5WKzAWYzA5WKYP16JebO1eLmTQkAguhoG2bO\nzEWXLqVnmvTlv00ACA8PL9d+NLBXAV//4/Ll+lV13X75RYlp0/yQmVkUyAnUagK9vrw/nglqPqg7\nUygEdOpkxpQpeYiJ4XH7NosLF6Q4flyKbduUuHWLg78/QevWFixcmA1ZiUk/ggBMm+aHPXvkMBgY\nBAcLSE/nkJbmfLFr0sSK//u/O6J554v48t8mUP7Afq8Nr1OUT/vuO3WxoA4ADCwWAp2OL7HdncoE\n9aI2XHmPUb6LiMnE4v/+T4nERAlatrQiIUGOtDQODEMcUzNNJuDXXxUICfHDjBnO66d+/rkWK1eq\nYbHY901NLV7Wu/79l8PlyxLExtL5kWWhgZ2iqoDBwODHH1W4cEGKjh3NeP55+yDj7duuzU2rlUXX\nrnoEBgo4e1aKxERJmVkXK6YoSIsFbLFtjJvt4q5dk+LaNQ5FQ3cl59sTwuDoUdc5+nv2yB1B3bWs\nd8nlpHA8gioLDewU5WXp6SwGDQpCYqIUhDDYsUOJdetUWLMm082dnPbW6TvvFGDZMjXUaoK//2ZQ\nUOCuBe9py7sksde5C+KenqP0LiWxjl/XoC6ucWNrmXP8KTsa2CnKyz75xA8XL95tmVqtDI4ckeG7\n79RQqwWRnDEM/vpLhmeeCS5MBMaA4wikUgFWq1igLArC3u5vr/q+++bNXdMHREfbcOmS852qCoWA\n+vVtyMpiwXFAbKwN8+dnV3n5fIVXAvs333yDEydOwN/fH3PnzvXGISnqvnXtmuvXihAGX3+thVIp\n3uK8dUvi1HXB8wx4HggNteHOHa6wpVs88DIIDOSRn8/AZqvKWcvuLh6e/WoICODxyCNWTJ+e5/Lc\nZ5/l4t9/Jbh8WQKrlUFAAI8ePUyYOzcXej0DloVXFyJ5EHglsHfp0gU9e/bEokWLvHE4irqvqVTi\nwTs/n3W7SpB4/hemcBqk+GvkcoJevUxYs0ZdwZKWhcDfX4DBwMJqrXgXTYcOJsyaled2/dTatQX8\n9tsdbN+uwJUrUvTpY0TTpvZ9NRoa0CvCK5f6pk2bQqPReONQFHXfe+UVPQID3eXP9bS7w/3+oaE8\n3ngjH5W7o5QU++d6brOZwWOPmSGTVaxvu2FDewqFshbFlkqB/v1NeP/9fEdQpyqu2vrY4+PjER8f\nDwCYPXs2goODq+vU1U4ikdD63ae8UbdhwwCOEzBmDAuTyZOphYAnUxHPn5ehe/daHrxGDAO5XIDZ\nLH4Mk4nFsWNyWD3KrEsQE0Pw7LME779PoNMFVaJ8nvHlv01PVFtgj4uLQ1xcnOOxL99E4Os3Sfhy\n/bxVt169gM6dA7Frl7Kcr7AH1qAgHjqdALMZuH5dAvdB294H742FNczm0n+4u3bDlK5lSyu2bs0A\nx9lnwVTnn4ov/20C5b9BieaKoagqMmdOLpo3tzi6MSQSAWV1m4SH89i7905h9kdvzFLxtJum4t06\nAQE8XnpJj9WrM8uRgZKqSjSwU1QVCQkRsGNHBpYsycaHH+aiTh3XZF8lFQXEvn2N8E42xopcHCp2\n3pAQAVevSvDSSzqMHh3gkrqXqj5e6Yr56quvcOHCBeTn5+ONN97AgAED0LVrV28cmqLuaxwHPPWU\nGcePS3HjRtnNWLlcwJIlKty8yRUuc1e5FAIajVDKjU5iGISG2hASIiAtjUVWFgdBKE8ZCJKTOdhs\n9vnoZ8/KkJQkwfbtGZBKRfYm9mRoGzaoEB7OY8gQPZYt0+DoURk4Dnj6aSOGDTMUZrGkPOWVwD5+\n/HhvHIaifNLSpWosX64Bz5cdpc6ckeHIETm8kT9doRDw6ad5mDLF34MkY4DJxGDXrgw8/XQwMjJK\nCxHF57gzLhehixel2LJFgRdfNLm88t13/fHrr0rk59vL9dVX2sLxAvsxTp6U4vp1CaZOdZ33TpWN\n/laiHjiJiRLMmaPF+vVKWErPAusV27crylwUuojJxKJ4sKyM8HABAwYY8c477qZEil848vNZHD4s\nhdFYufNbrQzOn3fNDXPihBS//XY3qAMovOjdPZ89sZgCBgNtslcETSlAPVA+/NAP27crkZ3NgeMI\nlixR48cfsxEZ6YXpJW4YjTXTfkpN5dCxYwiys4tfLIpzf7PUqFGBCAlxP3ed4wTwfOn1Uqt5xMW5\nttY3bVIiL6/s9yQ7m0VaGot69arus/FVtMVOPTCOHpViyxYVsrPtfc48z+DiRRkmTvT36nkIAb7/\nXo1+/XTo3TsYubmltTo96W4p7772/YxGFsnJUuTklL2IR0lpaRL8+y+HsDCbYx+WJVAoBDRubClz\neT6plCAykscXX2jRs2cwxowJQEYGgxs3ONSqxYNhyq5LcDCP8HAa1CuCttipB8bPP6tEW4piuV0q\nY+5cDZYs0Th1vygUAiwWBoLAQKkUEBgooGlTK06ckHqQopeBTsejoIApvKHI9YIhlRKPbiZiWUAQ\nxPPB5ORwePhhC0aM0CMpSYI+fUy4fFmCX39VICuLg0ZDnJasUygENGxoRUSEAEEADh6UO96Ds2dl\n+P13BZRKAoXCvrhIacvd+fktDqS3AAAgAElEQVQJeOEFA+Ty8teFuosGduqB4W5pNrnce/lIeB74\n9VelS586zwMvvmgAxwG9e5vQpYsZDAMMHBiEAwfEvobiwbZePRuuXZPgzh22sOwCYmJs0GoJwsJ4\nJCRIceeOyDSUUjzzjBH79smRl+fasr9wQYqICBvq1OHx889K/Pmn83iBVsujdm0BajXBs88a8frr\nehACdOsW4vIemEwsTI6eGQKVSijsQ2ecjteunQVDhxrQtavZo3pQd9HATj0w/vtfPbZsURbe0Wkn\nkRB06uS9AGI0MqKJvqxWFgcPyvHww1YEBvKOaXyvvaZHQoLMJUOjTEZc8pQHB/O4do3DnTt3A7DZ\nbE9ru2lTJhgGiI0N86i8gsBALgfeeScf06b5u0xt5HkGO3cq4S5fu8nEYvToXLzwwt2+dLMZbpOd\n3cWgTh0b+vQxYvlyNQoK7L9mAgMJWra00qBeSbSPnXpg6HQCvvwyB61aWRAebkP9+lYMHqzHRx95\nb0qdWk0QHCz+y+DmTQl27lRi+HAd9u2zzxbp2tWMli1d+06sVgZarVC4YhBB3bo2tG9vxp07rm2x\n5GQOK1bYl6aTyTy/07RxYysGDDBAqXT3WvezdOwzX5x/IcjlKHXgtYjNBuj1DPLyWNhsLASBwfXr\nEixZosGRI5796qCc0cBOPVDat7dg27YM7Nt3B3/+eQeffZbn1dvfGQZ4440ChIQUH/RzDpjp6RwW\nLtQ69l+1KguRkc4ZDQlhoNczGDzYfov+H3/cwYABBkilrgFTr+cweXIAevYM9jh3TGiogFdeMWDd\nOlWFpjdyHMGuXUoMHBiEI0dkjjqNGZOPWrWK18n1otGggQ1//y13+ZWQm8vihx+qKhXxg4EGduqB\npFIRSKqoI7JfPxPWrs1E//6GwuDmGjCL326v0RAEBLgGbEFgkJwsQZcuFsjlBL/9pgTj9lZMBhYL\ni9xcrlwzTgD7LJf16zOgUhGcOCEr5x2mxRHwPINr1yQ4cECBUaMCcOGC/U3t3duMdesy8eKLBvTs\naUT37qbCGTaAUimgRQsLvvgiV3SpPMBdfnqqvGgfO0VVgSZNbFi4MAcLF2owe7YWJYN7YKBzIFer\nxSNcUbfO5Mn+WLdOVa7gy3EAzxNH0LT317u24Tp1MqFhQ3sTv1kzG7ZtK89SewR16thgNrNOff0A\nkJoqwfz5WixZYl/CrmFDHl99leN4Pj2dxe7dctSpw+OJJyxgGKBVKwvOnpU6BXKtVsDLL+vLrCfl\nHm2xU1QVGjFCj2bNnPvQdToecXFGZGbe/foNHapHQIBzP0qdOjaMG1cAQQD+/rv8LWqbjSkMlAxk\nMoJHH7VAInG+cISG8k7L1L36qh5NmzqXMyCAR+3aVrDs3XnsDRvakJBwB/Xriy+GkZPjPqSEhgoY\nNMiIjh0tjsHjKVPyEBdngk7HO+r8yit6PPFENdwS7MNoi52iqpBKRbBuXSY+/1yLy5eluHaNg9nM\nYOZMfyxfrkFcnBmffZaLvn1NMJsZrFqlQn4+i9BQHhMn5iEigofFAg8W7HBmsbCwWBgMHGjAgQMy\nGAwShIRYMWpUAWJi7l5I7OXMwsyZWly9KoFGQ/DGGwXo0MGCI0ekOHFChq5dTYiNtb8mOtreP15S\ngwYercgBuRz48cdspKRwuHGDQ7NmVgQF0eXwKoshxF0vV9W6detWTZy2Wvh6sn9frl9V1m3xYjXm\nzPFzmsaoUAiYOTMXAwcaS33t88/rXAKpVCpALicoKHCXMsDu4Yct2LkzA0YjA4bRQSbLAFvJ3+qZ\nmSwGDAjCxYtFuWAImjWzYv36TAQE1Fxg9uW/TYAutEFR95zduxUuc9NNJhbbt5e9ytKMGblo0MDq\nGBgNCuIxYoQBhw7dQVRU6WuENmpkf14qJdi/n8G77/pj9WpVpRKg6XQCtmzJxPjx+ejd24h3383H\n5s01G9Spu2hXDEXdB5o0sWHnzgysX6/ErVscBgwwoH59e7fI449bCtMiOF80ZDIBzZrZ8OmnuTAa\ngf/8R4dTpySwWKTYuJFg9WoV1q7NhL9/xYKxVkvw3nv5la0aVQVoYKeoahIXZ8KxY1KnGSoKhYCe\nPY04c0aKiAj7eqfuKJUEr7xicDwWBHsK3F69jLhzh8Xp0zLk5dnzyTRubMPLLxsQF2cGywJffKEt\nnGduD/48z+D0aRlmzdJi9mya89zX0MBOUdXk9df1uHRJgn375Lhzx57lMCSEx+LFWty+zSIoSECH\nDhZ8+WVOmTdNJSVxePPNQCQlSWC1MqhXz4YPP8xFbCyP2FgrFArn/U+elEKsHz4xkd7h6YtoYKeo\nasIwwNy5ucjIYJGczOHOHQbvvBPkyDh56xaLLVs41KnDl9nF8fbbAU6LWFy5IsWCBVr88UeGS1AH\n3M+Td59G4K5165TYuFEJi4VB06ZWTJ6cD42G9qXfy+jgKUVVs+BgAa1bW7F5s9oljbDNxuDAAddV\nh4q7eZNFSoprm+zaNQni48Xz3I4enV8izQEQGMjj1VdLvxHo66/V+PhjP/z1lwLHjsmxcqUGgwcH\nQSg7FQxVg2hgp6ga4i44lnUjEsdBdLoiw0B04WgAaNHChhkzctC2rYCoKBseecRSeHOQ+yyKggBs\n2qRyWQz73Dmp2wsIdW+gXTEUVUMGDDBg/365U95yhiFo3br0lLVhYfYc7CVv6dfpeDz5pOtSdEX6\n9DFj2DBbued5GwwM8vJcLzImE4sTJ2R46imaWvdeRVvsFFVDevQwY9AgA8LD7fPMg4J4PPWUCR9+\nWPYUwkWLshEScnfZOsCeFXHWLD+vlU+tJqKzdDQaHp07u7+AUDWPBnaKqkGffpqH337LwMqVmdi+\nPQPLl2dDVnoXOwB7d4w9O+XdFrXZzGLnTgVycryTGZFh7LluivK42M9L0LatBe3aeZY6gKpetCuG\nompYSIiAbt0869a4eFGC1FTXr29aGovkZIno4h0VMWCAEfXr27BkiQZGI4MOHUxo186KW7c4RETQ\nhabvVbTFTlH3oQYNbAgNdQ2swcECoqK8G3BbtbJi6dJs9O1rxLp1arzwgg69ewdj8OCgUhekpmoO\nDewUdR8KDxfw+ONmp3S8MpmAJ580IyjI+3MRU1NZzJ5tz1BpMrHIyOCwd68C773n7/VzUZVHu2Io\n6j61YEEOYmNt2LdPDoYBunc34bXXqmaBih9/VIt2/dgXyQDcLuxE1QivBPZTp07hhx9+gCAI6Nat\nG/r16+eNw1IUVQqWBcaOLcDYsQVVfi6bmwSSdAm7e1Olu2IEQcD333+PSZMmYd68eTh06BD+/fdf\nb5SNoqh7xPDhBtE+/dhYK22t34MqHdivXLmCsLAw1KpVCxKJBB06dMDRo0e9UTaKou4RderwGDs2\nH9HR9rnzWq2Atm3NmDs3p8zXUtWv0l0xWVlZ0Ol0jsc6nQ6XL1922S8+Ph7x8fEAgNmzZyM4OLiy\np75nSSQSWr/7lC/XDahc/d5/Hxg1SsDffxOEhQEPPcQA0JX5uurk659feVU6sIutrMeI/DaLi4tD\nXFyc47EvL1/l68tz+XL9fLlugHfq16KF/b/34tvk659ftS2Np9PpkJmZ6XicmZmJwMDAyh6WqgJM\nVhZgLH1tzXIzmSA9dQrczZveOR5FUV5T6cBev359pKamIj09HTabDX/99Rcee+wxb5SN8hLp0aMI\n7tMHoXFxCO3aFQGjRwPmiidwYr7/HiFPPQVd//4I7tULQS+/DEZfNdPsKIryXKW7YjiOw6uvvoqZ\nM2dCEAQ8+eSTiIyM9EbZKC9gCgoQOH48JCkpjm3c9euAVIqcr77y+HjcjRvgpk8Hm5pq32A2g9uz\nB/4TJyJn4UIvlZqiqMrwyjz2Rx99FI8++qg3DkV5mXLtWnDFgjpgTxslO3YM4HmUuQZbCeply+4G\n9WKkZ85UopQURXkTTSng47iMDJGVLgFYrfbA7smxrlyB/P/+T/zJwkF0Jj8fXHKy/fgURdUIGth9\nnGHQIPAi07/4yEiUKz9sITY1FUFDh0J644bo89YmTeD/7rsI6d4dIU8/jZCnnoLqxx8rWmyKoiqB\nBnYfx0dHQz90KPhatQAARCKBNTYWOXPm2HcQBLC3boExGEo9jnbePEivXXPZTjgO5g4dwEdEQLVh\nAyQ3boDNzYX00iVov/wSkrNnvV4niqJKR5OAPQAK3nkHhkGDoNy6FXxYGEx9+gBSKRTbt0O7YAHY\ntDQQtRrmDh2Q+/nnov3u3O3bose2NmqEzA0bEPz002BKJBThMjOhWbYMOQsWVEm9KIoSRwP7A0II\nD4f+zTcdj7l//4XftGmQFA2EZmaCu3ULxM8PeVOnurze2rgxFLt3u2zno6Ls/+MmSxRTiWmVFEVV\nDO2KeUCpv/nmblAvxNhskB06ZH9ACGT790O1dCm4pCQUjB0Ly0MPOe1vjY5G3qRJkB45Yl/SvgRB\npYJhwIAqq0NpGKPR48FhivIVtMV+rzIaIb10CXxYGITC/vHi2Dt3AIsFQkSEfQMhUC9ZAuWOHWAM\nBtgiI5E3Y4Z9kFQEky++YDJjNILJy0PQkCGQnj8P1mgE//XXMHXvjswNG6BZtAjqq1dhCA5Gwdix\n8J80CbKEBHAFBSAMAzAMGEEAHxoKY69eMHft6rW3pDxkhw7Bb/ZssKmp9u6lLl3sv0BY2oahHhw0\nsN+D1MuWQbVyJbibN0ECAmBp1QrZX38NyOVgMzMR8OabkF65Aths4CMjkfP555Dv3g3twoVgCwdB\npYmJkCckIP3gQQihoc4nMJsh/ecfEMBlKiSbkwP/KVMgP3bMsY3LzITyl19g6tIF+R9+CHlwMPIy\nMqD68Uco9uxx9K0zhACEwNSuHXIWLLh70akmbHo6AiZMgKRY2mjJ9esgcjnyJ02q1rJQVE2izZh7\njOTCBWgWLID06lWwZjO4tDQofv8dfp98AgAIePNNKA4dApeWBi4zE7JTpxA4diyU27Y5gnoRVq+H\n7oUXnLZxly8j+JlnIP3nH/H57YRAKjKThbVaEfDBB2Dy8hzb5MWCutO+xX9JlIFNS4N22jT4v/02\npJVM96xevNgpqAMAY7FAvndvpY5LUfcb2mK/x6iXLQOXleW0jSEEsuPHwaalQXrpkstrJFevQlCr\nRY/H3bwJ9uZNCLVrQzt9OjQ//gjGYnF7fkYQQNx0W3C5ufCbMQOcVougM2cgO3FCdD8il7s9PmCf\nE69ZtAjS8+chuXwZXHY2AEC5cycM/fsjb+bMUl/vDucmqx8dwKUeNDSw32MYdwN+PA//Dz4AWyyT\npoPNBqJUAjkiix4QAjYnB36zZ0O5aZN4K734oerWhal7d0gvXrR3rZSg3LQJrNEId4kIBLUahuee\nE32OycqC39SpUP7+O1iRLJNsXh6U27dDP2IE+JiYMkrqyjBgAOQ7d4IrkZDMMXOHoh4QtCvmHqMf\nNgy8v+vK76zBAMUff4ARmX3CR0Uhe9Ys8ZY2y4LJzoZi+/ZSgzoBYAsLQ86sWSh4+23wdeqI7icW\nkIsfgw8JgfGFF6D96COEtm8P3QsvQHLyJLgrVxDSty/UhRcGd7jMTASMGQPdiy8i8PXXIbl40fn8\nGRlQrlsH2YEDLjNxLI8/DlOfPhAK3z/CcbA2boycWbNKqTlF+R6GiK2UUQ1u3bpVE6etFpVN9q+Z\nO9dxFycfEADrww9DkpICSYnb+QkAQadD7qefwtSvH3TPPgv58eMu+4BlRS8IRXg/PxhefBH5U6YA\nUikAQHrkCIL++19wxX4hCDIZ2FK6cQCA12jsvxL0eseFRJBIwEdFQZqUVGbdSw7o2sLDkbV0KWwt\nW0Izfz5Uq1ZBcusWBIUCtthYZP34o8vgsOT8eSi3bYOtfn0Y+/XzKHWCry/UQOt3fyvvQhs0sFcB\nb/xxMTk5kJ46BT4yEkJwMEK6doVE5O7P3HfegX7CBACA7rnnID9yxONzWRo1QsaePY7HbHo6AsaP\nh/TcOfu0SIkEtthY8P7+UFZwIFJsBk55mZ58ErnTpiH4ueecLjQAYOraFVk//VSu4zBGI1Tffw/Z\n6dOw1auHgjffBCmxKIyvBwZav/tbeQM77WO/R5GAAFi6dHE85iMiXAI77+cH48CBd1+jUFToXNJL\nlxDcqRMKRo4El5YG5a5dkJ07d3cHiwWCUomC8eOhOHDA/ThAKUrtBpLLYYuIAJufD+7OHZfn2cxM\nqFeudAnqACBJSrJnlhRZjtHp/Ho9dAMGQHr6tGPsQLFrFzLXrKn2aZkUVdVoH/t9whQX59KHzlgs\n4G7fhvToUQQNGgQuJQXEw/zqQGF+9qQkBL7/PvznzoW0eFAvJD13DoGjR1coqJfGGhWFtAMHcOfA\nARj69xfdRwgKEp2CCdj70YsHdcZggHrRIgSMHg3VihVAYdeR5uuvITt1ymlAWHrlCvxmzPBibSjq\n3kBb7PcJ+cGDLv3krMmEoCFDQORySNLSHNuJRAJBrQabm+tR9wdT4r9O58rLc5rDXpwgl4Ox2SoW\n9JVKR4tZP3QoVBs2OE33tNWujbzx4xFY2N1UHCl83lHGzEzoXnoJksIZPcodO6D85Rdk/fyz6MUK\ngMu8d4ryBbTFXt0IgfTwYSjXrhVdicgdd3OxuZwcp6AO2HO+gONEA7QglaIigyplzagRPBigdDpu\nfj7A85CcOgXd4MGOoE5gv2DoR4wA37AhWJE1VRkAtmIrd2k//dR+41XRoh82G+THj0OzaBF4nU70\n/IJWW6FyU9S9jLbYqxGTm4ugV16x52AxGOz5VPr2RV7hXaWlsTZp4nSbf5nncrOCkeDvDyEwENLL\nlys8mFkSV3jRKW2A1N1zbH4+tF98AVlCAqTFlvBjYL+Y+c2YAdXateADA8GVuIAJGg3MrVs7HktK\nLAFYRHrqFHJnzYI8IcGphc4HB6Ng5Mgy60dR9xs6K6YKuBuZDxg9GqotW5y2EZaFqWNH5H75JYSw\nMLfHZAoKENqxI7j09HKVgQ8MdNzRWVJRkK3MTBVPCRwHKBROLe/i5yccV2pXjk2nA0OIU4ueSKUg\nAQEgcjmsDRpAduwYuIICl9ca+vZFzjffQHL6NPzmzAF35w4Ef38UjBwJc/fuTvv6+qwKWr/7G53u\nWIPc/XGFdOsGaYkbbopYGzZExubNLtPviuOSkhD89NPgSmRm5LVal20AQBhG9O7RmmBp0gQ5X30F\n3eDBYLOyAEHw+KKif+45MDwPxZ9/ghUJ4GJ4lQqZ27fD1rhxufb39cBA63d/K29gp33s1YhI3Pd8\nSS9fhubrr90+L//tN/h//DGEkBDw/v4gDAM+MBCmjh2RP3IkBJG7Tisa1L19KRBYFjnz5sF/yhT7\n4tpugnpZ5+Xy82F4+WXHTJdynbtWrXIHdYryFbSPvRpZ2re3D+656XKQJCeLblcvWmRPyVvYKicM\nA2uLFsiePx+Cvz9qtW4NtpQ7Sz1BAJjat4f82DGwbvrpPcZx8P/4Y0gvXCh1NyEkBGxWltv3h0tK\ngmr5crfjB2IIHRylHkA0sFejvI8+ApOTY0+xKzLLxdaokeuLbDaoNm50BHXA3hLnrlyx37izZEmZ\nt/l7Snbhglfnq7NWK+RHjpTaIhdkMhSMGAFbw4YIHD0arMnk9DwBIE1OhjQ5udy/KAjDwFJs1gxF\nPShoV0x1kkiQ+9VXyFy1CnyJVZEsTZrA1KULAsaMQeBrr0Hx22/2nCvZ2WBFBkG5/Hwofv8dsjNn\nvFpEBvb0vKXllvE2wrLQDx0K/ZgxMPfsieylS2F+7DHwOh34wECXQd6igd+ifyWPRWCf8WLq3h15\nH39cTbWgqHsHbbHXAGuHDshYtw7aefPAZmXBVr8+bFFRCHr9dcdt8/I9e2B89lnkfv45hMBAl1vt\nCctCvWoVGINBdHZLdc54KS935eEDA8EajZAePgy/zz+H5MoVMFYrBK0WRKkUnd3DwH4xNLz0EhR7\n94LNzATx80PBsGEgQUHg69Rxm6GSonwdnRVTBTwemed5hHTvDmliovPmoCBkbN0Kxc6d0C5YcLeP\nHWXfMHSvBXV3ipdVkEjAiqzI5I61QQNkbNlS6kwiT/n6rApav/tbtcyKSUhIwIQJE/DSSy8hqRwp\nWSlx7O3bYEX+GLmsLMj37oV+1Chkz5sH05NPwtyhAwQ/v9IPWIF8MTWl+AXIk6AO2HO9hPTsCfXi\nxXc3EgLF5s0IHDYMgSNGQLZ/v3cKSlH3kUoF9sjISLz77rto0qSJt8rzQBKCgkRnbwgqFaxNmwIA\nzL16IWvVKmSuWQMSEFD6Ab2cqKsivP0zUKw/HbDnetEsWQKu8I5S/w8+QMC770L5xx9Q7tyJoJEj\noZk/38uloah7W6UCe506dcr904AqhVIJU5cuLvlWrA8/DGvbts77SqWwljEv+17ohhHKuvhUQP7o\n0faFPErg0tOhWrkS7M2bUMTHO82oYfPyoNy4EShl1SaK8jXVNngaHx+P+Ph4AMDs2bMRHBxcXaeu\ndhKJxPP6LV4MISoK2LkTsFhAmjcHM3cugsXmYa9YAeGll8CcPQtkZ98Tgbw4IpGADB0KYfNmMDdu\neK18qpgYsLVqASJ3nSpDQqC4fNklnwwASNLSEJKfDxIZWeY5KvTZ3Udo/R4MZQb26dOnI0dkkeSB\nAweidbEETGWJi4tDXFyc47EvD3BUeADn9dft/4qYzfZ/YtauBZecDN0zz0DiJidMjbHZwC1YAMB7\nvx4YAPqsLEgfegiqEuM5tshI3Hn+eahWr4afRGLPblmc0QjD+vXQjxlT5nl8ffCN1u/+5rUVlKZM\nmVLpwlBVg4+OBlQq4B4L7FXxC8IWHg7jgAEwDBsGxmiE9OxZMEYjhPBw5L3/PtTffQfNd9+5BnUA\njCBAvWYNDMOGgYh05VCUr6Hz2O8jTF4eNPPnQ5qYCD4kBAXjx0MIDARu3hTd39Ppg/cSwrL2JGY8\nD75uXeSPGgWh8Cd29g8/2FMP5OaCj4oCLBb4TZ8umrO9CHftGmSHD8PcrVt1VYGiakylAvuRI0ew\nfPly5OXlYfbs2YiOjsbkyZO9VTaqGKagALoXX3Rai1S1aRMEuVw0i6Pg74/ct99GwIwZoq3Ymsar\n1WD1evHFQORyZK5YAYbjwGZlwdy5s8usISEoCAgKAgBwGRmid+cWRzQa8KWkRaYoX1KpwN6mTRu0\nadPGW2WhSqH59lvnBaZhXyGIKwzahGEAqdSe9bFOHRj+8x8gIKBCS+RVJcIwEAIDkbloEQInTYK0\nROIzAsDSoQOsHTuW+5h8aCiEoCCnJfVKsjZpAlvh1FGK8nU0V8x9QlJGZkSGEBjj4nBn717ciY8H\nU1AA/0mT7HlfUDgPnPEsvFfFLckMIWBzciA/ehQFw4fD2rixfbk+joOgUsHQvz+yli3z7KAyGQz9\n+zstc0cACGo1bNHRMPbogazly50WvaYoX0b72O8TfN26Ze7DWK32/SwWqDZsAGsw3H0OQE1kjxBL\nb8AIAvy+/BKQSmGLioKxb1/IEhLAZWRAuWsXuIwMZC9d6lHKXf24cbA1agT12rWA1Qpzp07Qv/aa\n/S5cGtCpBwwN7F7CZGWBS0uDLSamSo5f8NZbkP/5J6RXr4o+TyQSmJ98EgDAZmSAvX3btYwentMb\n4dDdMRgAsFohvXLFnvSr6AmzGYr9+6F79llkxMd7lB7B3KsXzL16Va7AFOUDaFdMZdlsCBg7FiE9\nekDXty9CuncHWziH25uEwEBYWrSAoFLZbwBiWceqSbxGA9OTT9pXF4J9wQrmHmmlluc3glhJpZcv\nQ7Fjh7eLQ1EPBBrYK0n72WdQbt0Kya1b4PR6SJOSwM2ZA4mX86RrZ8+Gavt2sAYDGJsNjCCA+Puj\nYNgwZK1ciewffrjbupVKwet0Xj1/RQn+/hXqq2cIgez48TL3kx08CF3//gh94gno+vSBcs2aCpyN\nonwLDeyVJE9IcFltiMnIgOa777xzAkIAmw3yfftcloQrylNubdvWuR/ZZAJfq1aVDH56ytq8OVAi\nB055EIkE5s6dS92HS0pCwPjxkB8+DElyMuQnT8J/5kwotm2raHEpyifQwF5Z7lYaqux6oYRAM3cu\nQuLiENqhAyRXrojuxublubwuaNgwyE6frrIpjp5cMKxNmpSZtEzs+IK/v/2iUArtggWQpKY6bWNz\ncqD66SePzkdRvoYOnlaStXlzl/nlxM/PPo+8EtSLF0Pz7bdgS8lKKKjVMAwYAM2CBZDv3QsAsMXE\nQHbsWIWCenkX6BC9qUgigRAUBEl6umObtWFDFLz1Fsy9esH/7bchTUmxn4fjXH7lCFIpGKsVTOHx\nucxMBA0ZgowdOwCJ+J8pK5LDCIDTbCCKehDRFnsl5X36KUydOkHw9wdgz2kijBgBiwc32IhR/Pqr\naFAnRQOmOh2M/ftDtX49tHPnQn74MOSHD0P188+lXgwcxxHZJhawCcuCFPbdl9ZStzVqhKwffoCx\nRw+Y27aF/sUXkbl+PYhaDUXh1Eteq4XloYeQM306bMWWrRMUChCp1OX80sRE+9qvbpjbthWdm2+L\nji6lpBTl+2iLvZKIUomstWshuXgRkqtXYWndGkFNmgCVzDBXPKd4cZZHH4Wpe3eYevUC0WgQ0quX\nU8qAkqkF3CnP0nq22rWhHzoUQq1akO/eDeWvv7o/nl4PW4sWyF6+3Gl7cFwcpP/84zgfe+4cVJs2\nIWPHDuiefx7ctWtgTSbxC43FAumlSxB/JwD9iBFQ7N4N2YkTYCwWEIaBLTYWeZ98UkrtKMr30cDu\nJbbGjWHzsC+51OPVqwfpP/84bRPkcuhffRWmvn0BALLDh8GWWOTaG/hatWBt0gRsbi4Ue/fC3LEj\ncubNg/TCBZcUAEXY/HxwN26AL5bzXHLxIqSJiU4XEQaA7ORJKLZsAXfjhiNJmdiFhg8IgLF3b/cF\nlcuRuW4dFFu2QLFvH29muDAAAA1bSURBVKwPPQTD0KEgSqXnlaYoH0ID+z0qd+ZMSFJSIElMtGc4\n1Ghg6dQJpmeecexja9gQfO3akLjJ7lgWt9kfZTIoDh1yzMKRHT8OSVIS8qZNg9/UqZAkJ7sEYi4r\nC/Jdu2D4738d2+R//AFGbHCZ5+H3+edgLRb3ZVOpYOrevez8LhIJTC+8ANMLL5S+H0U9QGgf+z1K\nCA3FnV9/Rc6cOSgYMQJZK1Yge+lSgL37kQlBQTB36FChaY22unWRPX8+LLGx9gyRsM9EMbdtC5jN\nTlMrGZsN8r/+grVZM2T89huISJZEQaGArX59p22WRx91m5+mtAFOIpHA2K8fcufN86hOjNEI9eLF\nCHjrLSg2b74n1n6lqJpAW+z3MpkMxkGDUNpQqH7ECCi3bgVTovVbPNiXDK18YCAyV68GHxMDc79+\nYAoKID19GnxYGLisLOhEWr9sejokKSmwtGsH0qsXyMqVTjNbiEYDy+OPO73G2qEDhNBQl+Xqypp5\nw9hskJ4+7VGOFzYtDUH/+Y+964cQKLZvh3XtWmSuWlWhefQUdT+jLfb7nK1JE/tKSiUIISHIXrTI\n3moutp0PDkbO7Nngi+W0KQrKfP36sDZsKJq3nA8Ph61RI/v/f/klBD8/p+fZrCz4f/SR84sYBnf+\n+APmFi0gKJUQ3ExbFMPm5rq/R0CE3yefQHbxomPwmLVYIEtIgGrlynIfg6J8BQ3s9zuJBHkffABb\nseyPtjp1kPfRRzD164fM9etRMH48TJ06wdirFzJ//BHmPn3cHo4EBMDUuzcEtdqxTVAqYerZ0764\nBQBm40aXG6MYQYD8r79cbswSdDpk/vorbicmQl+s/93pnCLbhNBQp26nskgK58i7lOnQoXIfg6J8\nBe2K8QHmnj1xp317KNevB8PzMA4Y4AjCUCqR/957Hh0vb+pUWB59FMqNGwEAxv79YXr2WcfzTEqK\nyw1GAACTCYzZDCKVuj7HcTAMGwbVmjXgSl4USuzKa7XIHz3aozITlUp0uxAY6NFxKMoX0Ba7jyD+\n/jC89hr0b7xxN6g77UCg/vZb6Pr1Q3CfPvCbNAmMuxuZBAFgWRCtFramTWHu1Mmpv1sYOBC8yDmE\n8PBSF4vmIyNRMH48bCEh9iK52c8WEwNzz55ujyPGMGiQ4yYxx3HCw1EwbpxHx6EoX0Bb7A8Iv08+\ngeqnn8CazQDsc8mlSUnI/Pnnu0HbbAb377/wmzoV8r/+cuyr3L4dmd9/Dz421r5fo0Yw9u8P5caN\n4Apv67dGRSF3ypQyy6EfORKGQYMgO3gQmm+/hfzECdedKjAP3fjCC4DRCPXPP4PNzQUfGor8996z\nL3ZNUQ8YGtgfAIzRCEV8vCNQF5GcOgXpiROwtmoF9TffQLVuHbhbt8AYDE7dI5LkZPhPm4asYilx\n86ZNg2HAAKhWr4YQEgL98OEgAQHlKg/x84O5d29w6emQnTvnNKOHcBws7dpVqJ7GIUNgHDKkQq+l\nKF9CA/sDgM3IAFMyCyQArqAA0nPnwBgM0H79tX0mihucyE1QtmbNkPfZZxUul2HoUMiOH4d83z5w\nmZngAwNhadMG+ePHV/iYFEXRwP5A4MPCIAQHg8vKct6u08H8xBPwmzWr1KAOAKTYLBmvYVnkLFwI\nLjkZ0hMnYKtbF4rDh6FZsACGwYMhiEy7pCiqbHTw9EEglUI/ZAj4YjNEBLkcpi5dwNevX2bueEGt\nhrEwP40TiwWq1asRMG4clD//XOEc9Hy9eiAqFYLGjoXfrFnw+/JLBPfpA+WKFRU6HkU96GiL/QFh\nePVVWB9+GJrvvwfMZhj79IGpf38AgKlnT8j373fK3UIACAEB4KOiYOzbF/qRI52Ox+TnQzdwIKRn\nz4LheSi3bIFqzRpkrV3reeue5+H3xReQ3Ljh2CRJTYV2yRKYnn++1Jk2FEW5ooH9AWJt3RrZrVu7\nbDcOHAh5QgLke/eCy8yE4O8Py6OPIuv77wG5XPRY2s8/h+zUKcdjxmaD/PhxaObNQ37JO1DLILl8\nGdy//7ps///27i8kqiyOA/j3NrP9caJZdcBWQ0IdF8TFiKKS5qFyCSKiIsSBHnpyWakeJLCI9EGI\ngZwlNox8sIgpCgrFhyJoELeHbMtxJ0Qp0g0TUySnwXbKmjv37EO7w0Y6M3qve53j9/M0c5l77u/H\n4JfxzLlnLMPDWN7djY8//jin8YiWOgY7AYqC8K+/wvLnn1j++++IlpZC/eGHhKd8MzAw4/HlfX1z\nvrxmt3++wSgS+eK4yMiA5nDMeTyipY7BTnGxggJ8+M8eMolos0y3aLPcAZpwrO++Q7SkBJbffvvi\nuPr994hu2DDn8YiWOl3B7vP5EAgEYLVakZOTg5qaGtgWYvUELTqR6mos/+OPL1baxBwO/PXzz/Ma\n721LC76trcU3/f2ApkEtKkL4l1/mtMMjEX2mCJHib6nN4OnTpygtLYXFYsG1a9cAAIcPH07p3Nev\nX8/3souew+HAG50/jbeY/dvfyvZ2rG5txbK3b6FlZeHdTz8l3GAsJaoKCAHMtN/M/2CpvHeykr2/\n3NzclF6n6xN7WVlZ/HFxcTEePXqkZzhKM9MHDmD6wAFjB53D1r5ENDPD1rF3dnZiA+dDiYhMl/Tj\nUWNjI8L/bPT0X1VVVdj8z9K5trY2WCwWuFyuWcfx+/3w+/0AAI/HA4fEqx2sViv7S1My9wawv6VC\n1xw7AHR1deH+/fuor6/HilnWPM+Ec+zpS+b+ZO4NYH/pLtU5dl1TMcFgEB0dHairq5tTqBMR0cLR\n9U1Va2srVFVFY2MjAMDpdKK6utqQwoiIaH50BfuFCxeMqoOIiAzC3R2JiCTDYCcikgyDnYhIMgx2\nIiLJMNiJiCTDYCcikgyDnYhIMgx2IiLJMNiJiCTDYCcikgyDnYhIMgx2IiLJMNiJiCTDYCcikgyD\nnYhIMgx2IiLJMNiJiCTDYCcikgyDnYhIMgx2IiLJMNiJiCTDYCcikgyDnYhIMgx2IiLJMNiJiCTD\nYCcikgyDnYhIMgx2IiLJWPWcfPPmTfT09EBRFNjtdtTU1CArK8uo2oiIaB50Bfu+fftQVVUFALh7\n9y5u376N6upqQwojIqL50TUVk5GREX/88eNHKIqiuyAiItJHEUIIPQPcuHEDDx48QEZGBhoaGrBm\nzZoZX+f3++H3+wEAHo9HzyWJiCiBpMHe2NiIcDj81fGqqips3rw5/ry9vR3RaBSVlZVJL3ry5Emp\nw539pS+ZewPYX7pLtb+kc+xnzpxJ6YLbt2+Hx+NJKdiJiGjh6JpjHxsbiz/u6elBbm6u7oKIiEgf\nXatirl+/jrGxMSiKAofDkfKKmIqKCj2XXfTYX/qSuTeA/aW7VPvT/eUpEREtLrzzlIhIMgx2IiLJ\n6Jpj10Pm7Qh8Ph8CgQCsVitycnJQU1MDm81mdlmG6e7uxq1btzA6OoqzZ8+isLDQ7JIMEQwGceXK\nFWiahl27dmH//v1ml2SYixcvore3F3a7HV6v1+xyDPfmzRs0NzcjHA5DURRUVFRgz549ZpdliE+f\nPqGhoQGqqiIWi2Hr1q3JVx8Kk0QikfjjO3fuiJaWFrNKMVwwGBSqqgohhPD5fMLn85lckbFGRkbE\n6OioaGhoEIODg2aXY4hYLCaOHj0qxsfHRTQaFSdOnBAjIyNml2WY/v5+MTQ0JGpra80uZUGEQiEx\nNDQkhBDi/fv34vjx49K8f5qmiQ8fPgghhIhGo+LUqVPi+fPnCc8xbSpG5u0IysrKYLFYAADFxcUI\nhUImV2SsdevWSbe0dXBwEGvXrkVOTg6sVivKy8vx5MkTs8syTElJCVavXm12GQsmMzMTBQUFAIBV\nq1YhLy9Pmr87RVGwcuVKAEAsFkMsFkual6ZNxQBfb0cgo87OTpSXl5tdBiURCoWQnZ0df56dnY0X\nL16YWBHN18TEBF6+fImioiKzSzGMpmmoq6vD+Pg4du/eDafTmfD1CxrsybYjcLvdcLvdaG9vx717\n99LqrtVUtlpoa2uDxWKBy+X6v8vTLdWtJGQhZlj1K9N/kUvF9PQ0vF4vjhw58sWsQLpbtmwZzp07\nh0gkgqamJrx69Qr5+fmzvn5Bg13m7QiS9dbV1YVAIID6+vq0DIhU3ztZZGdnY3JyMv58cnISmZmZ\nJlZEc6WqKrxeL1wuF7Zs2WJ2OQvCZrOhpKQEwWAwYbCbNscu83YEwWAQHR0dqKurw4oVK8wuh1JQ\nWFiIsbExTExMQFVVPHz4EJs2bTK7LEqREAKXLl1CXl4e9u7da3Y5hpqamkIkEgHweYVMX18f8vLy\nEp5j2p2nTU1NX21HIMtyx2PHjkFV1fiXVU6nU6ofIHn8+DEuX76Mqakp2Gw2rF+/HqdPnza7LN16\ne3tx9epVaJqGHTt24ODBg2aXZJjz589jYGAA7969g91uR2VlJXbu3Gl2WYZ59uwZ6uvrkZ+fH/8P\n2e12Y+PGjSZXpt/w8DCam5uhaRqEENi2bRsOHTqU8BxuKUBEJBneeUpEJBkGOxGRZBjsRESSYbAT\nEUmGwU5EJBkGOxGRZBjsRESS+RsZmkNgmsgvLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_train[:, 0], x_train[:, 1], c=clusters, cmap=cm.bwr)\n",
    "plt.axis([-3, 3, -3, 3])\n",
    "plt.title(\"Predicted cluster assignments\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has correctly clustered the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarks: The log-sum-exp trick\n",
    "\n",
    "For a collapsed mixture model, implementing the log density can be tricky.\n",
    "In general, the log density is\n",
    "\n",
    "\\begin{align*}\n",
    "  \\log p(\\pi) +\n",
    "  \\Big[ \\sum_{k=1}^K \\log p(\\mathbf{\\mu}_k) + \\log\n",
    "  p(\\mathbf{\\sigma}_k) \\Big] +\n",
    "  \\sum_{n=1}^N \\log p(\\mathbf{x}_n \\mid \\pi, \\mu, \\sigma),\n",
    "\\end{align*}\n",
    "\n",
    "where the likelihood is\n",
    "\n",
    "\\begin{align*}\n",
    "  \\sum_{n=1}^N \\log p(\\mathbf{x}_n \\mid \\pi, \\mu, \\sigma)\n",
    "  &=\n",
    "  \\sum_{n=1}^N \\log \\sum_{k=1}^K \\pi_k \\, \\text{Normal}(\\mathbf{x}_n \\mid\n",
    "  \\mu_k, \\sigma_k).\n",
    "\\end{align*}\n",
    "\n",
    "To prevent numerical instability, we'd like to work on the log-scale,\n",
    "\n",
    "\\begin{align*}\n",
    "  \\sum_{n=1}^N \\log p(\\mathbf{x}_n \\mid \\pi, \\mu, \\sigma)\n",
    "  &=\n",
    "  \\sum_{n=1}^N \\log \\sum_{k=1}^K \\exp\\Big(\n",
    "  \\log \\pi_k + \\log \\text{Normal}(\\mathbf{x}_n \\mid \\mu_k, \\sigma_k)\\Big).\n",
    "\\end{align*}\n",
    "\n",
    "This expression involves a log sum exp operation, which is\n",
    "numerically unstable as exponentiation will often lead to one value\n",
    "dominating the rest. Therefore we use the log-sum-exp trick.\n",
    "It is based on the identity\n",
    "\n",
    "\\begin{align*}\n",
    "  \\mathbf{x}_{\\mathrm{max}}\n",
    "  &=\n",
    "  \\arg\\max \\mathbf{x},\n",
    "  \\\\\n",
    "  \\log \\sum_i \\exp(\\mathbf{x}_i)\n",
    "  &=\n",
    "  \\log \\Big(\\exp(\\mathbf{x}_{\\mathrm{max}}) \\sum_i \\exp(\\mathbf{x}_i -\n",
    "  \\mathbf{x}_{\\mathrm{max}})\\Big)\n",
    "  \\\\\n",
    "  &=\n",
    "  \\mathbf{x}_{\\mathrm{max}} + \\log \\sum_i \\exp(\\mathbf{x}_i -\n",
    "  \\mathbf{x}_{\\mathrm{max}}).\n",
    "\\end{align*}\n",
    "\n",
    "Subtracting the maximum value before taking the log-sum-exp leads to\n",
    "more numerically stable output. The $\\texttt{Mixture}$ random variable\n",
    "implements this trick for calculating the log-density."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
